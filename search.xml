<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[设计模式系列——装饰者模式(DecoratorPattern)]]></title>
    <url>%2F2018%2F04%2F19%2Fdecorator-pattern-deep-learning%2F</url>
    <content type="text"><![CDATA[所谓的设计模式，其实是对面向对象编程思想中的一个转变，是在繁重需求任务中做到可扩展，高度灵活，并且适应业务开发而产生的一种思想。今天我们说的修饰者模式，是一种动态地往一个类中添加新的行为的设计模式。就功能而言，修饰模式相比生成子类更为灵活，这样可以给某个对象而不是整个类添加一些功能。 当有几个相互独立的功能需要扩充时，这个区别就变得很重要。在有些面向对象的编程语言中，类不能在运行时被创建，通常在设计的时候也不能预测到有哪几种功能组合。这就意味着要为每一种组合都得创建一个新类。 好吧，现在把我当做一个小偷，我需要对大师的画进行临摹，我临摹的画有很多类型的 可能是油画，可能是水墨画，也可能是沙画等等。我临摹完了这些画之后，需要对画进行装饰一下才能卖个好价钱，比如对画添加一个画框，这个画框可能是木框，可能是钻石框(好吧，我承认我比较奢侈)。但是添加完了画框之后，我可能又想为其添加一些签名，例如齐白石老先生的签名，例如梵高的签名，这样才能卖个好价钱呀！反正我会想尽一切办法去添加画本身内容外的装饰。那么我们传统手法怎么做呢？我们学过OOP思想——类的继承的话，就会想着不断继承下去，例如我的油画：class OilPicture，然后添加了木框：class WoodFrameOilPicture : public OilPicture, 然后添加了齐白石老先生的签名:class BaiShiWoodFrameOilPicture : public WoodFrameOilPicture。想一想，不同的组合竟然会产生各种不同的子类，这种不断继承来添加新特性的继承地狱是在是太愚蠢了。现在我们可不可以想出一个新方法，让我的油画可以自由组合，又可以脱离这种继承地狱的方法呢？这就是我们今天要说的主题——修饰者模式。修饰模式是类继承的另外一种选择。类继承在编译时候增加行为，而装饰模式是在运行时增加行为。 首先我们定义图画类：123456789101112class Picture &#123;public: Picture() &#123;&#125; virtual ~Picture() &#123;&#125;; virtual int32_t getWorth() = 0; // virtual std::string Description() = 0; virtual bool Contain(const std::type_info&amp;) = 0;private: Picture(const Picture&amp;) = delete; void operator=(const Picture&amp;) = delete;&#125;; 这个图画类我们定义了四个接口：int32_t getWorth(): 通过添加不同的装饰品后获取图画的价值.std::string Description(): 这幅图画的描述文字.bool Contain(const std::type_info&amp;): 用于判断图画是否添加了某种装饰品. 我们临摹的图画主要有两种，一种是油画，一种是水墨画12345678910111213141516class OilPicture : public Picture &#123;public: ~OilPicture() &#123;&#125; int32_t getWorth() override &#123; return 500; &#125;; std::string Description() override &#123; return "一副好看油画!"; &#125; bool Contain(const std::type_info&amp; info) override &#123; return typeid(OilPicture).hash_code() == info.hash_code(); &#125;&#125;; 12345678910111213141516class InkPicture : public Picture &#123;public: ~InkPicture() &#123;&#125; int32_t getWorth() override &#123; return 500; &#125; std::string Description() override &#123; return "一副好看的水墨画!"; &#125; bool Contain(const std::type_info&amp; info) override &#123; return typeid(InkPicture).hash_code() == info.hash_code(); &#125;&#125;; 我们首先模仿的油画和水墨画都定价为500块钱，然后添加他们的描述。好了现在这样我们也可以去卖了，但是这个价值不高，我们需要添加一点装饰品，让画看上去高大上一点。 这里我们可能需要为画添加一个签名，这个签名统一命名为签名装饰品，它是图画的一部分12345678910111213141516171819202122class AuthorPictureDecorator : public Picture &#123;public: AuthorPictureDecorator(Picture* p, std::string author) : picture_(p), author_(author) &#123;&#125; virtual ~AuthorPictureDecorator() &#123; delete picture_; &#125; std::string Description() override &#123; return picture_-&gt;Description() + PetPhrase(); &#125; int32_t getWorth() override &#123; return picture_-&gt;getWorth() + AuthorWorth(); &#125;; virtual int32_t AuthorWorth() = 0; virtual std::string PetPhrase() = 0;protected: Picture* picture_; std::string author_; // 作者的名字&#125;; std::string PetPhrase(): 作者的口头禅Picture* picture_: 这个变量用于记住我们要修饰的图画对象.int32_t getWorth(): 图画的价值加上签名的价值，就是我们的图画真实的价值了.int32_t AuthorWorth() 作者签名的价值 好了，但是我只会模仿齐白石老先生跟梵高的签名：1234567891011121314151617181920212223242526class AuthorQiBaishi : public AuthorPictureDecorator &#123;public: AuthorQiBaishi(Picture* p) : AuthorPictureDecorator(p, "QiBaiShi") &#123; &#125; int32_t AuthorWorth() override &#123; if (Contain(typeid(InkPicture))) &#123; // 齐白石老先生只会画水墨画 return 1000; &#125; else &#123; return -500; // 假的画 &#125; &#125; bool Contain(const std::type_info&amp; info) override &#123; if (typeid(AuthorQiBaishi).hash_code() != info.hash_code()) &#123; return picture_-&gt;Contain(info); &#125; return true; &#125; std::string PetPhrase() override &#123; return "我是" + author_ + "皮皮虾我们走！"; &#125;&#125;; 1234567891011121314151617181920212223242526class AuthorFanGao : public AuthorPictureDecorator &#123;public: AuthorFanGao(Picture* p) : AuthorPictureDecorator(p, "FanGao") &#123; &#125; int32_t AuthorWorth() override &#123; if (Contain(typeid(OilPicture))) &#123; // 梵高大石只会画油画呀 return 2000; &#125; else &#123; return -500; // 假的画 &#125; &#125; bool Contain(const std::type_info&amp; info) override &#123; if (typeid(AuthorFanGao).hash_code() != info.hash_code()) &#123; return picture_-&gt;Contain(info); &#125; return true; &#125; std::string PetPhrase() override &#123; return "I am " + author_ + " 不要跟我谈钱，我就是穷!"; &#125;&#125;; 恩，很好，添加了签名貌似更值钱了，不过添加一个画框那就更完美了，顺便挣一波画框的钱，哈哈哈，我真是生意天才!这里我们可能需要为画添加一个画框，这个画框统一命名为画框装饰品，它是图画的一部分：1234567891011121314151617181920class PictureFrameDecorator : public Picture &#123;public: PictureFrameDecorator(Picture* p) : picture_(p) &#123;&#125; virtual ~PictureFrameDecorator() &#123; delete picture_; &#125; int32_t getWorth() override &#123; return picture_-&gt;getWorth() + FrameWorth(); &#125; std::string Description() override &#123; return picture_-&gt;Description() + Features(); &#125; virtual int32_t FrameWorth() = 0; virtual std::string Features() const = 0;protected: Picture* picture_;&#125;; std::string Features(): 画框的描述Picture* picture_: 这个变量用于记住我们要修饰的图画对象.int32_t getWorth(): 图画目前的价值加上画框的价值，就是我们的图画真实的价值了.int32_t FrameWorth() 画框的真实的价值 但是我这边材料只有两种，一种是木头，一种是钻石，额确实有点奢侈，有什么办法呢~：123456789101112131415161718192021class DiamondFrame : public PictureFrameDecorator &#123;public: DiamondFrame(Picture* p) : PictureFrameDecorator(p) &#123;&#125; ~DiamondFrame() &#123;&#125; int32_t FrameWorth() override &#123; return 30000; // 钻石框定价三万块钱，恩，这肯定能好好挣一波 &#125; bool Contain(const std::type_info&amp; info) override &#123; if (typeid(DiamondFrame).hash_code() != info.hash_code()) &#123; return picture_-&gt;Contain(info); &#125; return true; &#125; std::string Features() const override &#123; return "闪闪发光!"; &#125;&#125;; 1234567891011121314151617181920class WoodFrame : public PictureFrameDecorator &#123;public: WoodFrame(Picture* p) : PictureFrameDecorator(p) &#123;&#125; ~WoodFrame() &#123;&#125; int32_t FrameWorth() override &#123; return 5000; // 木头我也要定价为 5000 块钱，我不管！ &#125; std::string Features() const override &#123; return "久远大自然的味道!"; &#125; bool Contain(const std::type_info&amp; info) override &#123; if (typeid(WoodFrame).hash_code() != info.hash_code()) &#123; return picture_-&gt;Contain(info); &#125; return true; &#125;&#125;; 好了，先定这两个装饰品吧，后面根据用户的要求，再去添加其他装饰品吧。 先看看客户A的要求：”你好，我要一副油画，有梵高大师的签名的”我：好的，没问题老板，嘻嘻嘻！12Picture* oil_pic = new OilPicture();oil_pic = new AuthorFanGao(oil_pic); 我：好了，老板，你要的作品~oil_pic，价值为2500块钱客户A：嗷，看上去加个图框貌似更好，我要个钻石框吧.我：好的，老板，老板大气！123Picture* oil_pic = new OilPicture();oil_pic = new AuthorFanGao(oil_pic);oil_pic = new DiamondFrame(oil_pic); 我：好了，老板，你要的作品~oil_pic，32500块钱客户A:嗷，完美~ 先看看客户B的要求：”你好，我要一副水墨画，有梵高大师和齐白石老先生的签名的”我：老板，你的口味比较独特呀，不过没问题~123Picture* ink_pic = new InkPicture();ink_pic = new AuthorFanGao(ink_pic);ink_pic = new AuthorFanGao(ink_pic); 我：好了，老板，你要的作品~ink_pic，价值为1000块钱，唉，往水墨画上加梵高大石的名字这种品位必须给你打折~客户B：不错不错~ 通过这样的装饰，我们可以随意添加各种各样并且不同种类的装饰品与此同时又不会影响到油画类和水墨画类本身的特性。 优点：通过使用修饰模式，可以在运行时扩充一个类的功能，例如签名功能，画框功能。原理是：增加一个修饰类包裹原来的类，包裹的方式一般是通过在将原来的对象作为修饰类的构造函数的参数。装饰类实现新的功能，但是，在不需要用到新功能的地方，它可以直接调用原来的类中的方法。修饰类必须和原来的类有相同的接口。 具体结构如下图： Component:抽象类的接口，例如我们的图画类Picture ConcreteComponent:是 Component 的子类，具体的需要使用类，实现了相应的方法，它充当了“被装饰者”的角色。例如我们的油画类和水墨画类 Decorator：也是 Component 的子类，抽象装饰者类的接口，内部有一个 Component 对象被持有用于被装饰，例如我们的画框装饰品类 ConcreteDecorator：是Decorator的子类，是具体的装饰者。由于它同时也是Component的子类，因此它能方便地拓展Component的状态（比如添加新的方法）。每个装饰者都应该有一个实例变量用以保存某个Component的引用，这也是利用了组合的特性。在持有Component的引用后，由于其自身也是Component的子类，那么，相当于ConcreteDecorator包裹了Component，不但有Component的特性，同时自身也可以有别的特性，也就是所谓的装饰。相当于我们的木头类和钻石类。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>存储结构</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跳表的深入浅出——SkipList]]></title>
    <url>%2F2018%2F04%2F16%2Fskiplist-deep-learning%2F</url>
    <content type="text"><![CDATA[跳表作为存储数据结构，在谷歌的数据库开源代码leveldb中被广泛使用，当然还有大名鼎鼎的redis。跳表的原理相当简单，只要你能熟练操作链表，就能轻松实现一个 SkipList。从而摆脱了红黑树，或者AVL树之类的复杂写法，因为这类数据结构体都要要考虑很多细节，要参考一堆算法与数据结构之类的树，还要参考网上的代码，相当麻烦。跳表是在很多应用中有可能替代平衡树而作为实现方法的一种数据结构。跳跃列表的算法有同平衡树一样的渐进的预期时间边界，并且更简单、更快速和使用更少的空间。 leveldb 存取数据，都在用 MemTable 这个结构体，而 MemTable 核心在于 level::MemTable::Table，也就是 typedef SkipList&lt;const char*, KeyComparator&gt; level::MemTable::Table。 SkipList 看名字就知道，跳表，是一种数据结构，允许快速查询一个有序连续元素的数据链表。这是一种 “以空间换取时间” 的一种做法，值得注意的是，这些链表都是有序的。 关于这个跳表，我查了一下作者(William Pugh)给出的解析: Skip lists are a data structure that can be used in place of balanced trees. Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees. 跳表是平衡树的一种替代的数据结构，但是和红黑树不相同的是，跳表对于树的平衡的实现是基于一种随机化的算法的，这样也就是说跳表的 插入和删除的工作是比较简单的。 也就是说核心在于随机算法，一个靠谱的随机算法对跳表是非常重要的。 现在我们来一边用代码加图解来分析一下跳表魅力！ 跳表数据存储模型跳表数据结构如下： 12345678910111213141516171819template &lt;typename Key, typename Value&gt;class SkipList &#123;private: struct Node; // 声明节点结构体 public: explicit SkipList(); private: int level_; // 跳表层数 Node* head_; // 跳表头部节点列表 unit32_t rnd_; // 随机数因子 // 生成节点方法 Node* NewNode(int level, const Key&amp; key, const Value&amp; value); Node* FindGreaterOrEqual(const Key&amp; key, Node** prev) const; &#125;; 节点数据结构：1234567891011121314template &lt;typename Key, typename Value&gt;struct SkipList&lt;Key, Value&gt;::Node &#123; explicit Node(const Key&amp; k, const Value&amp; v) : key(k), value(v) &#123;&#125; Key key; Value value; void SetNext(int i, Node* x); Node* Next(int i)； private: struct Node* forward_[1]; // 节点数组列表，这个比较重要，后面会详细介绍，如果不理解这个变量，就很难理解跳表了&#125; 通过图来看一下总体结构 ps:图中虚线链接表述数组关系，实现标识指针链表关系 上图假设 level 为 4 等级的一个跳表图，，forward_ 变量是一个指针数组，一边指向下一个节点(黑色填充箭头)的链表，一边又是这些链表的数组(透明填充箭头)这样的一个数据结构形成了我们需要的一个链表。 后面我们会称为图中竖向(dowm)节点为节点数组，横向(left)的节点为节点链表 初始化跳表首先为了实现这个结构，我们来初始化跳表12345678910enum &#123;kMaxLevel = 12&#125;; // 这里初始化默认跳表最大层数高度为12template &lt;typename Key, typename Value&gt;SkipList&lt;Key, Value&gt;::SkipList() : head_(NewNode( kMaxLevel, 0, 0)), rnd_(0xdeadbeef)&#123; // 将 head 节点数组全部初始化 for (int i = 0; i &lt; kMaxLevel; ++i) &#123; head_-&gt;SetNext(i, nullptr); // 设置第 i 层节点 &#125;&#125; 现在我们的结构就实现了下图的样子了 当然，这些节点都是空的就是了。NewNode 方法查看 插入操作插入操作分为两步： 查找每层链表，知道找到该插入的位置（因为要保持有序的） 更新节点指针和跳表高度 第一步：123456789101112131415161718template &lt;typename Key, typename Value&gt;typename SkipList&lt;Key, Value&gt;::Node*SkipList&lt;Key, Value&gt;::FindGreaterOrEqual(const Key&amp; key, Node** prev) const&#123; Node* x = head_, *next = nullptr; int level = level_ - 1; // 从最高层往下查找需要插入的位置 // 填充 prev，prev 为用来记录每 层（level）跳点的位置 for (int i = level; i &gt;= 0 ; --i) &#123; while ( (next = x-&gt;Next(i)) &amp;&amp; next-&gt;key &lt; key) &#123; x = next; &#125; if (NULL != prev) &#123;prev[i] = x;&#125; &#125; return next; // 返回第 level0 层最合适插入的节点位置&#125;; 第一步操作如图3.1 所示， 往这一跳表中插入 key=17 的操作， 可以看出跳表不断寻找跳点，记录跳点 (红色框框住的点，我们以下称为跳点)，寻找该插入的位置，例如 图3.1中运行上面代码后，返回了 next 为 key=12 的节点，因为 key=17 大于 12 ，小于 19。 图 3.1 第二步：12345678910111213141516171819202122232425262728293031323334353637template &lt;typename Key, typename Value&gt;bool SkipList&lt;Key, Value&gt;::Insert(const Key&amp; key, const Value&amp; value) &#123; /** 第一步实现*/ // prev 为用来记录每 层（level）跳点的位置 Node* prev[kMaxLevel]; // 查找每层链表，知道找到该插入的位置（因为要保持有序的） Node* next = FindGreaterOrEqual(key, prev); int level; // 不能插入相同的key if ( next &amp;&amp; next-&gt;key == key ) &#123; return false; &#125; /** 第二部实现， 第二步实现后的代码如图 3.2*/ // 产生一个随机层数 k level = randomLevel(); if (level &gt; level_) &#123; for (int i = level_; i &lt; level; ++i) &#123; prev[i] = head_; // 新增的层数初始化 &#125; level_ = level; &#125; // 新建一个待插入节点 next， next = NewNode(level, key, value); // 逐层更新节点的指针, 一层一层插入 for (int j = 0; j &lt; level; ++j) &#123; next-&gt;SetNext(j, prev[j]-&gt;Next(j)); // 该节点第 levelJ 层的节点指向 prev （跳点位置）的 levelJ 层链表指向的节点 prev[j]-&gt;SetNext(j, next); // 将 pre 跳点第 levelJ 层链表指向了 Next 第 levelJ 层的链表节点 &#125; return true;&#125; 上述代码中 randomLevel() 生成的层数，就作为了跳表的总层数，同时，也代表了这个新增节点的层数，例如 图3.2 中，节点 key=3，高度为1，key=6，高度为4。 图 3.2 randomLevel 随机层数生成setNext 设置节点链表 查找操作插入操作中的第一步就是我们的查找操作了，就不做解析了，直接封装一层代码123456789template &lt;typename Key, typename Value&gt;ValueSkipList&lt;Key, Value&gt;::Find(const Key &amp;key) &#123; Node* node = FindGreaterOrEqual(key, NULL); if (node) &#123; return node-&gt;value; &#125; return NULL;&#125; 删除操作在 leveldeb 中，跳表 SkipList 是没有删除操作的，leveldb 的跳表只是用来增加节点个查询节点，如果要删除某个节点，只是将某个节点标记为删除，因为删除操作又得重新计算 level 层数，更新每层的节点链表，这样太耗费性能了。 但是我们在这里还是实现一下跳表的删除操作，同样的，跳表删除和插入操作相同 首先查找到需要删除的节点 如果找到该节点，更新指针域，需要更新 level 的话，逐层更新每个链表 123456789101112131415161718192021222324252627282930template &lt;typename Key, typename Value&gt;boolSkipList&lt;Key, Value&gt;::Delete(const Key&amp;key)&#123; Node* prev[kMaxLevel]; Node* next = FindGreaterOrEqual(key, prev); int level = level_; if (next &amp;&amp; next-&gt;key == key) &#123; // 将每层跳点链表设置到 next 节点所指向的每层的链表 for (int i = 0; i &lt; level; ++i) &#123; if (prev[i]-&gt;Next(i) &amp;&amp; prev[i]-&gt;Next(i)-&gt;key == next-&gt;key) &#123; prev[i]-&gt;SetNext(i, next-&gt;Next(i)); &#125; &#125; // 释放该节点数组的所有内存 free(next); //如果删除的是最大层的节点，那么需要重新维护跳表的 for (int j = level_-1; j &gt;= 0 ; --j) &#123; if (head_-&gt;Next(j) == NULL) &#123; level_--; &#125; &#125; return true; &#125; return false;&#125;; 图4.1 如 图4.1所示，删除节点 key=17 时候的操作，先查找并返回 next 节点，检查 next 节点是否 key=17，如果是的是，则将逐层的跳点全部更新过来，并更新层数。 附属实现代码生成节点方法12345678910template &lt;typename Key, typename Value&gt;typename SkipList&lt;Key, Value&gt;::Node*SkipList&lt;Key, Value&gt;::NewNode(int level, const Key&amp; key, const Value&amp; value)&#123; size_t men = sizeof(Node) + level * sizeof(Node*); Node* node = (Node*)malloc(men); node-&gt;key = key; node-&gt;value = value; return node;&#125; 代码中 sizeof(Node) 为本身结构体所需要的内存分配，level sizeof(Node) 是为 forward_ 数组分配内存，因为要配 level 个节点链表。 在 leveldb 中使用了字节对齐的方式来分配这块内存，我这边并没有写出来，有兴趣的可以浏览一下源码。 我们假设 level = 4 图 6.1 代码生成了图6.1的结构，level0 节点的 forward_ 数组大小为4，leve1 ~ level3 都为空节点，但是分配了 8 个字节的指针内存 (64位操作系统)。图中虚线为数组引用表达，并不是指针指向。 随机层数生成数方法实现取自google开源项目leveldb的实现12345678910111213141516171819202122232425262728293031323334353637383940template &lt;typename Key, typename Value&gt;int SkipList&lt;Key, Value&gt;::randomLevel() &#123; static const unsigned int kBranching = 4; int height = 1; while (height &lt; kMaxLevel &amp;&amp; ((::Next(rnd_) % kBranching) == 0)) &#123; height++; &#125; assert(height &gt; 0); assert(height &lt;= kMaxLevel); return height;&#125;uint32_t Next( uint32_t&amp; seed) &#123; seed = seed &amp; 0x7fffffffu; // 防止负数 if (seed == 0 || seed == 2147483647L) &#123; seed = 1; &#125; static const uint32_t M = 2147483647L; // 2^31-1 static const uint64_t A = 16807; // bits 14, 8, 7, 5, 2, 1, 0 // We are computing // seed_ = (seed_ * A) % M, where M = 2^31-1 // // seed_ must not be zero or M, or else all subsequent computed values // will be zero or M respectively. For all other values, seed_ will end // up cycling through every number in [1,M-1] uint64_t product = seed * A; // Compute (product % M) using the fact that ((x &lt;&lt; 31) % M) == x. seed = static_cast&lt;uint32_t&gt;((product &gt;&gt; 31) + (product &amp; M)); // The first reduction may overflow by 1 bit, so we may need to // repeat. mod == M is not possible; using &gt; allows the faster // sign-bit-based test. if (seed &gt; M) &#123; seed -= M; &#125; return seed;&#125; 总体来说这个 level 层数的生成方法也不是随机的，根据 seed 不断被修改的次数来决定层数，换而言之就是 level0 节点数量来决定层数。 有关节点结构体的方法实现12345678910111213template &lt;typename Key, typename Value&gt;void SkipList&lt;Key, Value&gt;::SetNext(int i, Node* x) &#123; assert(i &gt;= 0); forward_[i] = x; // 设置数组节点&#125;template &lt;typename Key, typename Value&gt;void SkipList&lt;Key, Value&gt;::Node* Next(int i) &#123; assert(i &gt;= 0); return forward_[i];&#125; SetNext(int i, Node* x) 方法是设置 forward_ 节点数组第 i 层(level)的链表引用。例如图6.1 中，key=10 调用了 SetNext(4, Node where key = 20 and level = 4) 和 key=20 调用了 SetNext(4, Node where key = 40 and level = 4) 的表述。 图 6.2 Next(int i) 为取出某层节点链表的方法，这个应该不应解析了吧。 输出跳表结构1234567891011121314151617template &lt;typename Key, typename Value&gt;voidSkipList&lt;Key, Value&gt;::Print()&#123; Node* next, *x = head_; printf("--------\n"); for (int i = level_ - 1; i &gt;= 0; --i) &#123; x = head_; while ((next = x-&gt;Next(i))) &#123; x = next; std::cout &lt;&lt; "key: " &lt;&lt; next-&gt;key &lt;&lt; " -&gt; "; &#125; printf("\n"); &#125; printf("--------\n");&#125; Print 方法来输出查看当前跳表有哪些节点结构 参考资料：跳表SkipListSkip List（跳跃表）原理详解与实现]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>存储结构</tag>
        <tag>C/C++</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次进程的上下文切换需要多长时间]]></title>
    <url>%2F2018%2F04%2F13%2Fhow-log-does-it-take-to-make-context-switch%2F</url>
    <content type="text"><![CDATA[原文. 这个标题不自觉的挑起了我的兴致，我决定付出时间去找出答案。StumbleUpon公司的发布了这样一个假设，即随着Nehalem架构的所有改进(Nehalem架构被用在 i7 处理器上面)，上下文切换将会变得更快。对于这个假设，换做是你，将会如何设计一个测试并且根据你的经验来找到这个问题的答案？究竟一次上下文切换有多昂贵呢？(直接告诉你答案：非常昂贵！) 据我所知，所有的 CPU 都有一个恒定的时钟频率(定时器)。而所有的Linux内核都是由Ubuntu构建和发布的。 第一次尝试：利用系统调用(失败了)我的第一个想法就是连续的调用多次廉价的系统调用(system call), 计算出所有系统调用花费的总时间和平均时间。Linux 上最廉价的系统调用的触发函数貌似就是gettid。但是，得到的结果却证明了我的想法是多么的天真！因为现在系统调用实际上不会导致完全的上下文切换，Linux内核可用通过”模式切换”(“从用户模式到内核模式，再回到用户模式”)来完成系统调用。这就是为什么当我运行我的第一个测试程序时，vmstat不会显示上下文切换次数的明显增加。但是这个测试也很有趣，尽管结果这不是我最初想要的。什么是 vmstat？ vmstat: 命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。 源代码：timesyscall.c 的结果： * Intel 5150: 105ns/syscall * Intel E5440: 87ns/syscall * Intel E5520: 58ns/syscall * Intel X5550: 52ns/syscall * Intel L5630: 58ns/syscall * Intel E5-2620: 67ns/syscall 很好，从结果中看到，越是昂贵的 CPU 所表现的性能月好(但请注意，Sandy Bridge的成本略有增加)。但这并不是我们想要的结果。要测试上下文切换的成本，我们必须强制内核取消调度当前进程，然后调度另一个进程(进程切换)。为了对CPU进行基准测试，我们需要让内核在密集的循环中不做任何事情。How would you do this? 第二次尝试: 使用futex这一次我使用了滥用futex[RTFM]的方式。futex是大多数线程库用于实现阻塞操作（例如等待抢占互斥锁，信号量，条件变量等）的底层的Linux特定基元。如果你想了解更多关于futex的知识，可以阅读Ulrich Drepper所著的Futexes Are Tricky。不管怎么样，利用futex来暂停和恢复进程是非常容易的。我的做法就是fork出一个子进程，然后让父进程和子进程轮流等待futex。当父进程在等待状态的时候，子进程将其唤醒，然后子进程进入等待状态等待futex，直到父进程将子进程唤醒，然后父进程进入等待状态。就像乒乓球一样，你唤醒我，我唤醒你。 源代码：timectxsw.c 的结果： * Intel 5150: ~4300ns/context switch * Intel E5440: ~3600ns/context switch * Intel E5520: ~4500ns/context switch * Intel X5550: ~3000ns/context switch * Intel L5630: ~3000ns/context switch * Intel E5-2620: ~3000ns/context switch 注意：这些结果包含了futex系统调用的开销。 上述结果并不准确！在现实中，上下文切换是非常昂贵的，因为它与 CPU 缓存相关联(L1, L2, L3 (如果有的话), 还有 TLB!)。(ps:这些都是高速缓存了，TLB 是页表缓存) CPU 亲和力在 SMP 的环境当中，这个测试是非常困难的，因为性能的表现对于一个任务(task)是否从一个核迁移到另外一个核的影响是非常大的(特别是如果迁移跨越了物理CPU)。我再次运行基准测试，但这次我将进程/线程固定在单个内核（或“硬件线程”）上。让性能提速受限。 源代码：cpubench.sh 结果： 未完待续…]]></content>
      <categories>
        <category>计算机系统</category>
        <category>并发</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[静态库中Class的分类问题和符号冲突问题 (Xcode other Link Flags)]]></title>
    <url>%2F2018%2F04%2F13%2Fxcode-link-symbol-conflict%2F</url>
    <content type="text"><![CDATA[other linker flags 是 xcode 这个集成开发环境所特有的，目的是让连接器器 ld 除了默认参数外再根添加额外参数进行链接工作。 Object-C 链接特性: The “selector not recognized” runtime exception occurs due to an issue between the implementation of standard UNIX static libraries, the linker and the dynamic nature of Objective-C. Objective-C does not define linker symbols for each function (or method, in Objective-C) - instead, linker symbols are only generated for each class. If you extend a pre-existing class with categories, the linker does not know to associate the object code of the core class implementation and the category implementation. This prevents objects created in the resulting application from responding to a selector that is defined in the category. Object-C的链接器并不会为每个方法建立符号表，而是为每个类建立链接符号。这样的话静态库中定义了已存在的类的分类，链接器就以为这个类存在了，不会将分类和核心类代码关联（合并）起来，这样在最后可执行文件中，就会找不到分类里所定义的方法。 例如如下错误： 就看 log 可以看出，是 NSString 的一个分类方法 designByOhterLinker 找不到实现了，而这个方法，确实是一个静态库里面的一个分类方法。 如何解决这个问题？ 三个Linker 参数： -ObjC -all_load -force_load -dead_strip (8.27日更新) #####-ObjC ： This flag causes the linker to load every object file in the library that defines an Objective-C class or category. While this option will typically result in a larger executable (due to additional object code loaded into the application), it will allow the successful creation of effective Objective-C static libraries that contain categories on existing classes. 加入这个参数后，链接器会将静态库中的每个类和分类加载到最后的可执行文件，当然，这个参数会导致可执行文件比较大，原因是加载了更多的额外对象的代码到可执行文件当中去，但是这会解决 Objec-C 中静态库中找不到分类方法的问题。 上面说得很清楚，-ObjC 会解决静态库中已存在的类的分类问题，那么，如果分类存在与静态库，但是类并不在静态库的这种情况，该怎么办呢？ Important: For 64-bit and iPhone OS applications, there is a linker bug that prevents -ObjC from loading objects files from static libraries that contain only categories and no classes. The workaround is to use the -allload or -forceload flags. 说得很清楚，使用-all_load 或 -force_load 就可以解决上述问题。 #####-all_load：该参数把所找到的目标文件都加载到可执行文件当中去，但是这就存在一个问题了，如果两个静态库中，都使用了同一份目标文件（这是一个很常见的问题，例如大家的目标文件都使用了用以名字 base64.o）就会发生 ld: duplicate symbol 符号冲突问题，所以不太建议使用。 #####-force_load：该参数的作用跟 -all_load 其实是一样的，但是 -force_load 需要指定要进行全部加载的库文件的路径，这样的话，只要完全加载一个库文件，不影响其余库的可重定位目标文件的按需加载。 但是也有一种最头痛，就是当两个静态库中使用了相同的目标文件 上图的两个上图的两个 libMyOtherStaticLibrary.a 和 libMyStaticLibrary 中的 MyClass.o 类发生了冲突那么，这个时候有两种解决方法： 1、利用 -force_load 让链接器指定编译把其中一个静态库的目标文件，不加载另一个静态库的重复目标文件 具体做法： 但是这么做有一个弊端，如果这两个静态库同时都使用到了分类（基本上都会使用吧）那么如果只让编译器加载其中一个静态库的目标文件 （-force_load），而不将另一个静态库中的分类合并加载到目标文件的话，也是会导致运行的时候导致上述的崩溃问题。但是如果 -foce_load 两个静态库，又会有符号冲突，那么，怎么办呢？ 2、简单来说就是去除某个静态库中的重复目标文件，然后再打包 具体做法：1）通过使用压缩工具命令 ar -t 去查看两个静态库文件里的目标文件那些存在冲突如下： 很明显就是 MyClass.o 这个目标文件发生符号冲突了， 其实不这样看也行，反正编译的时候 Clang 编译器就就会有符号冲突的报错，上图 Xcode 报错的那个图就是很好的例子，可以看错那些目标文件重复了。 2）将其中一个静态库中的重复目标文件去掉，然后再次打包成静态库使用 首先利用 lipo 命令将其中一个iOS静态库的文件解压出来（因为iOS的静态库文件是一个将不同 CPU 架构静态库合并的一个打包文件）。 可以看出 libMyOtherStaticLibrary.a 中包含了 armv7 跟 arm64 两种架构的静态库文件 分别将两种不同架构的静态库文件提取出来 使用 ar 压缩工具分别将这两个不同架构的静态库文件与另一个发生冲突的静态库文件中的目标文件剔除出去。 通过上面命令看出已成功将 MyClass.o 剔除出静态库 利用 lipo 将两个不同架构的静态库重新打包封装成 iOS 的静态库文件 然后在 libMyOtherStaticLibraryOut.a 这个静态库重新放到工程当中去替换原来的 libMyOtherStaticLibrary.a Other linker flags 只需用 -ObjC 就可以了 编译，Successful!运行，完美！ #####-dead_strip （2017.8.27 更新）参数的作用在于解决我们上面可重定位目标文件（.o）中类符号的冲突问题，如果发生了这种情况，使用该参数就是一个非常快捷的办法了，让 Clang 编译器帮助我们去除重复符号的可重定位目标文件问题。但是使用这个参数却有一个问题，就是如果我们使用了改参数，就不能使用 -all_load 或 -force_load，认真想想也知道，如果我们指定了让编译器帮我们决定哪些目标文件该被链接，哪些不被链接（-dead_strip），那么我们就不能手动的强制地让所有目标文件都进行链接了（-all_load 或 -force_load）。如果是这样的话，我们又回到最初的问题了，-ObjC 会解决静态库中已存在的类的分类问题，那么，如果分类存在与静态库，但是类并不在静态库的这种情况，该怎么办呢？]]></content>
      <categories>
        <category>计算机系统</category>
        <category>编译链接</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>计算机基础</tag>
        <tag>xcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[白话并发——死锁]]></title>
    <url>%2F2018%2F04%2F13%2Fwhat-is-deadlock%2F</url>
    <content type="text"><![CDATA[文章主要带大家理解什么是死锁，死锁什么情况下会发生，还有解决死锁的方法。文章主要用 C++11 标准库中的 std::thread 来讲解。std::thread 底层上还是调用的POSIX的线程标准的 pthread。文中由头到尾通过孩子玩耍玩具的实力去带你理解死锁。 waht is Deadlock(什么是死锁)？ 试想有一个玩具，这个玩具由两部分组成，必须拿到这两个部分，才能够玩。例如，一个玩具鼓，需要一个鼓锤和一个鼓才能玩。现在有两个小孩，他们都很喜欢玩这个玩具。当其中一个孩子拿到了鼓和鼓锤时，那就可以尽情的玩耍了。当另一孩子想要玩，他就得等待另一孩子玩完才行。再试想，鼓和鼓锤被放在不同的玩具箱里，并且两个孩子在同一时间里都想要去敲鼓。之后，他们就去玩具箱里面找这个鼓。其中一个找到了鼓，并且另外一个找到了鼓锤。现在问题就来了，除非其中一个孩子决定让另一个先玩，他可以把自己的那部分给另外一个孩子；但当他们都紧握着自己所有的部分而不给予，那么这个鼓谁都没法玩。——出自 &lt;&lt;C++并发编程&gt;&gt; 一书 上面只是对线程死锁的一个概念描述，文中的孩子和玩具分别对应如下： 孩子——&gt;线程鼓和鼓锤——&gt;两个互斥量 当一对线程需要对他们拥有的互斥量做一些操作，其中每个线程都有一个互斥量，且等待另外一个解锁 。这样互相等待的线程就像孩子们一样，谁都无法开心的敲响这个鼓，因为他们都在等待对方释放互斥量。这种情况就是死锁。 我们对上面的例子进行代码形象化！ 构建对象例子说明首先是对玩具的定义： 123456789101112131415161718class Tool &#123;public: Tool(const std::string&amp; tool_nam) : tool_name_(tool_nam) &#123;&#125; friend void PlayDrum(Tool&amp; lhs, Tool&amp; rhs);private: std::mutex mutex_; std::string tool_name_;&#125;;/* * 尝试玩耍鼓锤 * */void PlayDrum(Tool&amp; lhs, Tool&amp; rhs) &#123; std::lock_guard&lt;std::mutex&gt; guard_a(lhs.mutex_); // 获取到了鼓或锤 std::lock_guard&lt;std::mutex&gt; guard_b(rhs.mutex_); // 获取到了鼓或锤 std::cout &lt;&lt; &quot;完成组成出玩具: &quot; &lt;&lt; tool_name &lt;&lt; std::endl; // 成功组成玩具，终于可以玩耍了。&#125; 玩具类中，每个玩具都拥有一个自己的名称和玩具的实体，而 mutex_ 互斥量就是对应的鼓或锤了，就是玩具的实体，而 tool_name_ 为玩具的名称，这样孩子们才知道他们究竟拿到的是什么玩具，毕竟孩子还小。 下面我们就实例化出鼓和锤这两个玩具12Tool drum(&quot;鼓&quot;);Tool hammer(&quot;锤&quot;); 嗯，看上去鼓和锤都有了，那么孩子又对应什么呢？ 上面说过孩子对应着线程实例，那么我们就必须有两个孩子（childen）, 而且两个孩子都想玩鼓和锤。 12345678910111213// 非常非常地想玩鼓和锤void WantToPlayDrum() &#123; PlayDrum(drum, hammer);&#125;void LeanDeadLock()&#123; std::thread childen1(WantToPlayDrum); std::thread childen2(WantToPlayDrum); childen1.join(); childen2.join();&#125;; 上面例子实例化了两条线程（两个孩子），他们都只想去玩鼓锤（WantToPlayDrum）。我们不妨再看看 PlayDrum 这个方法， 12345void PlayDrum(Tool&amp; lhs, Tool&amp; rhs) &#123; std::lock_guard&lt;std::mutex&gt; guard_a(lhs.mutex_); // 获取到了鼓或锤 std::lock_guard&lt;std::mutex&gt; guard_b(rhs.mutex_); // 获取到了鼓或锤 std::cout &lt;&lt; &quot;完成组成出玩具: &quot; &lt;&lt; tool_name &lt;&lt; std::endl; // 成功组成玩具，终于可以玩耍了。&#125; 上面整个例子这些写是没有问题的，因为他们都是非常有顺序的先拿鼓，再拿锤。不管是线程1（孩子1）还是线程2（孩子2）先拿到鼓，另外一个孩子必须等待拿到鼓的孩子先玩耍完，才能拿到鼓。 如何形成死锁但是这里出现了另外一个问题，当两个孩子想要获取的玩具顺序不一样的时候，又会怎么样 ？ 12345678910111213141516void WantToPlayDrum1() &#123; PlayDrum(drum, hammer); // 先拿到鼓再拿到锤&#125;void WantToPlayDrum2() &#123; PlayDrum(hammer, drum); // 先拿到锤再拿到鼓&#125;void LeanDeadLock()&#123; std::thread child1(WantToPlayDrum1); std::thread child2(WantToPlayDrum2); child1.join(); child2.join();&#125;; 上面例子中，线程1（孩子1）想先拿到 drum（鼓）再拿到 hammer（锤），而线程2（孩子2）则相反，那么上面整个例子又有什么问题呢？为什么会有死锁产生？ 这个时候我们还是得看 PlayDrum 这个方法，我们假设线程1（孩子1）先进入了 PlayDrum 这个方法，并且成功的获取到了鼓（lhs.mutex_），但与此同时，线程2（孩子2）又进入了 PlayDrum 这个方法并且获取到了锤（lhs.mutex_）。当线程1（孩子1）想要去获取锤（rhs.mutex_）的时候，发现线程2（孩子2）已经握在手上了，没办法，只能等待线程2（孩子2）玩耍完不要这个锤的时候，线程1（孩子1）才能愉快的玩耍。而线程2（孩子2）的情况则相反，想要去获取鼓（rhs.mutex_）的时候，发现线程1（孩子1）已经握在手上了，并且怒气冲冲的喊他给他锤，没办法线程2（孩子2）只能也怒气冲冲的喊线程1（孩子1），给他鼓。 图解： 孩子们都发现各自所需要的第二个玩具都给持有了，两个孩子唯有等待大家让出来了，当然，两个孩子都是倔强的孩子，到最后谁到拿不到鼓锤，大家最后都只能傻傻的站在原地。 解决上述死锁的方法这就是死锁的产生了，那么，这个时候就会有人站出来问，为什么孩子们这么笨，要一个玩具一个玩具的拿，他不是有两只手吗，不行还有两条腿，在不行就霸坑，直接抱着玩具箱找玩具，不让别人的孩子一起找。是的，我们这就顺着这种思路去实现代码——霸坑！我们重写孩子们想要玩玩具的过程： 1234567void PlayDrum(Tool&amp; lhs, Tool&amp; rhs) &#123; std::lock(lhs.mutex_, rhs.mutex_); std::lock_guard&lt;std::mutex&gt; guard_a(lhs.mutex_); // 获取到了鼓 std::lock_guard&lt;std::mutex&gt; guard_b(rhs.mutex_); // 获取到了锤 std::string tool_name = lhs.tool_name_ + rhs.tool_name_; // 成功组成玩具，终于可以玩耍了。 std::cout &lt;&lt; &quot;完成组成出玩具: &quot; &lt;&lt; tool_name &lt;&lt; std::endl;&#125; 细心的看客就会看到我们仅仅在玩耍玩具的代码中添加了 std::lock(lhs.mutex_, rhs.mutex_); 这一句代码，那么这句代码的作用是什么呢？实现固有顺序，当一个线程（孩子），想要玩耍鼓锤的时候，先把装着鼓锤的箱子拿走，然后再慢慢找鼓锤——std::lock，那么另外一个孩子也没办法，只能慢慢等他找到鼓锤并玩耍玩后才能尝试去获取鼓锤了。 可以看 std::lock 的内部实现： 先获取一个锁，然后再调用std::try_lock去获取剩下的锁，如果失败了，则下次先获取上次失败的锁。重复上面的过程，直到成功获取到所有的锁。 重复的玩具？看官看到这里心想，这人终于要说完了，但是万万没想到上面例子还存在一个坑。试想一下，当一个孩子想要玩耍两个锤或鼓的时候，会怎么样？不妨来看一看实现代码：123void WantToPlayDrum() &#123; PlayDrum(drum, drum);&#125; 当线程（孩子）要玩耍两个鼓的时候，我们就要调用 PlayDrum 方法了，通过 std::lock_guard&lt;std::mutex&gt; guard_a(lhs.mutex_) 获取了鼓，但是当调用 std::lock_guard&lt;std::mutex&gt; guard_b(rhs.mutex_); 获取鼓的时候，发现鼓没有了（因为由始至终都只有一个鼓），所以线程（孩子）只能等待或者说是期待吧，手中的鼓能够神迹的复制一个出来，但是这当然是不可能发生的啦， 所以线程（孩子）只能默默的等待了。 怎么解决这个问题？当然是不能让这种无中生有的事情发生啦！优化 PlayDrum 函数：12345678910void PlayDrum(Tool&amp; lhs, Tool&amp; rhs) &#123; if (&amp;lhs == &amp;rhs) &#123; // 1、防止两个相同的对象相互量相互等待，造成死锁 return; &#125; std::lock(lhs.mutex_, rhs.mutex_); std::lock_guard&lt;std::mutex&gt; guard_a(lhs.mutex_); // 获取到了鼓 std::lock_guard&lt;std::mutex&gt; guard_b(rhs.mutex_); // 获取到了锤 std::string tool_name = lhs.tool_name_ + rhs.tool_name_; // 成功组成玩具，终于可以玩耍了。 std::cout &lt;&lt; &quot;完成组成出玩具: &quot; &lt;&lt; tool_name &lt;&lt; std::endl;&#125; 这样我们就大功告成了，孩子们终于可以愉快“排队”的玩耍了，毕竟是法治，人人都得有素质嘛。]]></content>
      <categories>
        <category>计算机系统</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
        <tag>线程锁</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于iOS调用Shell命令]]></title>
    <url>%2F2018%2F04%2F12%2Fhow-about-ios-invoke-shell%2F</url>
    <content type="text"><![CDATA[一开始认为iOS是Unix系统，肯定是可以调用Shell命令的。但是后面发觉事情并不是那么简单。 确定是否能调用Shell命令的要项： 是否存在 Shell 程序 是否能使用多进程 (因为 shell 命令都是 fork 出一个进程进行处理的) 首先明白什么是 Shell? Unix shell，一种壳层与命令行界面，是Unix操作系统下传统的用户和计算机的交互界面。第一个用户直接输入命令来执行各种各样的任务。普通意义上的shell就是可以接受用户输入命令的程序。它之所以被称作shell是因为它隐藏了操作系统低层的细节。 意思就是 Shell 命令会执行系统的底层 API 进行，让用户通过简单得命令执行复杂的系统操作。 首先确定iOS是否存在 Shell 程序 (这个还真的要确认一下)，但是就目前的情况来看，iOS 并不存在任何 Shell 程序。 一开始我上网查找，找到最多的都是使用 system 函数123int system(const char *)system(&quot;ls -al&quot;) 后来一看，真机上毛输出都没有，返回结果是 0x7f00, 意思就是 没有权限操作，真是坑了个爹。 然后看一下系统，发觉这个函数在 iOS8 被抛弃了，系统建议用 posix_spawn 好吧，可能跟这个有关系 12345678910pid_t pid;char* argv[] =&#123; &quot;ls&quot;, NULL&#125;;int result = posix_spawn(&amp;pid, argv[0], NULL, NULL, argv, environ);perror(&quot;posix_spawn&quot;);waitpid(pid, NULL, 0); 等到的输出，一直是 posix_spawn: No child processes。很是绝望。 没办法，后来在 Stack Overflow 上面找到一个帖子。 Yes, you can but it is extremely limited, and ping will probably not work… Regardless use the system() and check gdb.But Quentin is right about using PING.NOTE: This is only useful for debugging and shouldn’t be used for actual apps. 一看，好东西，原来真机上不行，但是在模拟器上可以搞，原以为很开心的，因为起码能用，结果模拟器上使用system 函数输出如下：1dyld: dyld_sim cannot be loaded in a restricted process 很是无语呀，iOS 应用上无法使用多进程。 想了想，越狱行不行，通过越狱的话，就可以使用多进程了，如果没有 Shell 的话，直接使用 OpenSSH(OpenBSD Secure Shell),这样我们就可以通过远程连接来操作 iPhone了， 然后再通过 pc 进行 ssh 连接过去，然后就可以使用命令行了。找到了文章证实了想法。]]></content>
      <categories>
        <category>计算机系统</category>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>计算机基础</tag>
        <tag>思考</tag>
        <tag>Unix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastImageCache 架构分析]]></title>
    <url>%2F2018%2F04%2F10%2Fios-fastimagecache-opensource-interpretation%2F</url>
    <content type="text"><![CDATA[文章介绍本文章注重分析 FastImageCache 这个 Github 第三方图片IO库的架构和部分分析等等。对于 FastImageCache 很多同学或多或少都会听过，但是网上很多人说这是一个网络图片库，我只想说一句——“你们是来搞笑的吗？有用过吗？有看过一点点源码吗？”, 这个图片库跟网络半毛钱关系都没有，如果真的用过一点点示例的，根本不会说出这句话。 FastImageCache是Path团队开发的一个开源库，用于提升图片的加载和渲染速度，让基于图片的列表滑动起来更顺畅，来看看它是怎么做的。 加载图片过程iOS从磁盘加载一张图片，使用UIImageVIew显示在屏幕上，需要经过以下步骤： 用户应用程序调用 read() 函数尝试从物理内存/高速缓存中读取图像数据 CPU 模式切换为内核模式，内核应用程序尝试从物理内存/高速缓存中读取图像数据，如果存在则走步骤 3，如果不存在则引起缺页异常，由内核中的缺页异常处理程序确定物理内存中的牺牲页，将磁盘页作为新页调入到物理内存中，更新内存中的页表条目PTE，缺页异常处理程序返回用户应用程序，重新走第 1 步。(关于这部分知识可查看阅读CSAPP——虚拟内存篇) 内核应用程序将图片数据放在内核缓冲区，从内核缓冲区复制数据到用户空间。(关于内核态和用户态的知识，可查看阅读CASPP——进程篇) 创建 UIImageView，把图像数据赋值给 UIImageView 如果图像数据为未解码的PNG/JPG，解码为位图数据 CATransaction捕获到UIImageView layer树的变化 主线程Runloop提交CATransaction，开始进行图像渲染 6.1 如果数据没有字节对齐，Core Animation会再拷贝一份数据，进行字节块对齐。 6.2 GPU处理位图数据，进行渲染。 FastImageCache 分别优化了 3,5,7.1三个步骤： 使用mmap内存映射函数，省去了上述第3步数据从内核空间拷贝到用户空间和内核态的操作和用户态之间的切换消耗。 缓存解码后的位图数据到磁盘，下次从磁盘读取时省去第5步解码的操作。 生成字节块对齐的数据，防止上述第7.1步CoreAnimation在渲染时再拷贝一份数据。 接下来具体介绍这三个优化点以及它的实现。 内存映射什么是用户态和内核态？用户模式和内核模式上面这篇博客讲解了用户态和用户态不过是为了防止用户恶意操作操作系统中的数据和硬件而建立的CPU模式机制。这样当用户应用程序想要访问硬件设备的时候，都要进入内核态(一个内存地址空间跟用户态完全不一样的环境，这里可能会发生进程切换，但大部分情况是不会的)。 那么使用了 mmap 函数后会优化了什么？关于mmap, 内存映射说白了 mmap 就是将磁盘内存地址跟应用程序的虚拟地址一一对应的操作，在真正使用到这些数据前却不会消耗物理内存，也不会有读写磁盘的操作,只有真正使用这些数据时，也就是图像准备渲染在屏幕上时，虚拟内存管理系统VMS才根据缺页加载的机制从磁盘加载对应的数据块到物理内存，再进行渲染，让我们对文件的读写都可以直接在用户态进行，省去了用户态和内核态的切换和缓冲区之间的内存拷贝。(在 Linux 中通常用于多进程访问同一数据的时候进行共享内存的创建，这样就不用多次拷贝内核缓冲区字节到不同的应用程序当中，而且写入数据都能同步到不同的进程) 解码图像一般我们使用的图像是JPG/PNG，这些图像数据不是位图，而是是经过编码压缩后的数据，使用它渲染到屏幕之前需要进行解码转成位图数据，这个解码操作是比较耗时的，并且没有GPU硬解码，只能通过CPU，iOS默认会在主线程对图像进行解码。很多库都解决了图像解码的问题，不过由于解码后的图像太大，一般不会缓存到磁盘，SDWebImage的做法是把解码操作从主线程移到子线程，让耗时的解码操作不占用主线程的时间。FastImageCache也是在子线程解码图像，不同的是它会缓存解码后的图像到磁盘。因为解码后的图像体积很大，FastImageCache对这些图像数据做了系列缓存管理，详见下文实现部分。另外缓存的图像体积大也是使用内存映射读取文件的原因，小文件使用内存映射无优势，内存拷贝的量少，拷贝后占用用户内存也不高，文件越大内存映射优势越大。 Data Alignment 字节块对齐iOS高效图片 IO 框架是如何炼成的 中有讲到为何需要字节对齐，而且字节对齐的实现等等。 FastImageCache 架构实现通过阅读 FastImageCache 后，粗略的画出了以下这幅流程图，途中标识着这个框架的要获取图片的整体流程如何实现: 那么 FastImageCache 是如何实现上述流程的呢？关于的总体结构如下图： 上图中 ImageCache 是一个单例，用作管理整个图片框架系统。 FastImageCache 为了更好的读存图片数据，将所有图像字节大小相同的图片都放在一起，也就是所有格式相同的图片都放在同一个文件系统当中(这个后面会讲到)，而在 FastImageCache 中，imageFormat 分为 4 种格式：1234FICImageFormatStyle32BitBGRA,FICImageFormatStyle32BitBGR,FICImageFormatStyle16BitBGR,FICImageFormatStyle8BitGrayscale, ImageTable：每一种格式都对应一个 ImageTable 结构体，一个 ImageTable 更是一个真实的文件，可以叫做一个真实的文件系统，命名为 xxx.table 文件放在沙盒的 Cache 文件夹当中。 Chunk：ImageTable拥有多个 Chunk，而 Chunk 被设置为 2M 大小的内存块，存在于 ImageTable 文件系统中，获取的时候通过内存映射 mmap 作为共享内存映射到用户空间的虚拟内存当中。 Entry： Chunk存在着多个Entry, 因为操作系统当中访问磁盘，都是以磁盘页和内存页的方式存在于磁盘和物理内存当中，在 64 位 Unix操作系统中，一般为 4KB，这个大小可以通过设置操作系统更改，所以 Entry 为了加快访问数据字节访问获取速度和节省由于页不对齐而导致的 CPU 周期增加的消耗，就采用页对齐的方式。Entry 中存储着一个图片的字节数组，和 Meta(ImageCache用到的一些 UUID 的唯一图片标识)，而 ImageData 为了避免发生 copy_images 的发生，更是采用了字节块对齐。 而这些实现细节，可以查看iOS高效图片 IO 框架是如何炼成的。 文献参考：《iOS图片加载速度极限优化—FastImageCache解析》]]></content>
      <categories>
        <category>第三方框架</category>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>第三方框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iOS高效图片 IO 框架是如何炼成的]]></title>
    <url>%2F2018%2F04%2F10%2Fios-efficient-image-io%2F</url>
    <content type="text"><![CDATA[当我们使用图片存储的时候，难免会涉及到文件IO，GPU渲染等问题，文章注重从计算机操作系统方面深入浅析地讲解如何优化图片IO的速度，提高 iOS 中 UIImageView 的渲染效率和内存优化，这对我们做多图片相册等应用会非常有帮助，而且让我们把阅读CASPP——进程篇和阅读CSAPP——虚拟内存篇这两篇文章学到的内容进行实战应用。 图像数据拷贝？当我们使用以下 Object-C 代码从网络中获取图片并加载到 UIImageView 上12345678910NSURL* url = [NSURL URLWithString:@"https://img.alicdn.com/bao/uploaded/i2/2836521972/TB2cyksspXXXXanXpXXXXXXXXXX_!!0-paimai.jpg"]; __weak typeof(self) weakSelf = self; NSURLSessionDataTask *task = [[NSURLSession sharedSession] dataTaskWithRequest:[[NSURLRequest alloc] initWithURL:url] completionHandler:^(NSData *data, NSURLResponse *response, NSError *error) &#123; UIImage* image = [UIImage imageWithData:data]; dispatch_async(dispatch_get_main_queue(), ^&#123; [weakSelf.imageView setImage:image]; &#125;); &#125;]; [task resume]; 运行上面代码，通过 Instrument 的 TimeProfile 查看 CPU 消耗情况： 上述图片中发现了两个问题： 应用程序使用了 CA::Render::copy_image, 这是因为 Core Animation 在图像数据非字节对齐的情况下渲染前会先拷贝一份图像数据，当我们使用 imageWithContentsOfFile 也会发生这种情况。 应用程序使用了 CA::Render::create_image_from_provider, 这个方法实际上是对图片进行解码，原因是 UIImage 在加载的时候实际上并没有对图片进行解码，而是延迟到图片被显示或者其他需要解码的时候。这种策略节约了内存，但是却会在显示的时候占用大量的主线程CPU时间进行解码，导致界面卡顿。 那么如果解决上述两个问题，我们使用 FastImageCache 这个第三方库加载图片，官方Demo一开始的 FICDPhoto 加载图片的方法为使用 imageWithContentsOfFile, 这会导致 CA::Render::copy_image 的图像数据拷贝，所以更改为以下方法：12345678910111213141516- (UIImage *)sourceImage &#123; __block UIImage *sourceImage = [UIImage imageWithContentsOfFile:[_sourceImageURL path]]; if (!sourceImage) &#123; pthread_mutex_lock(&amp;_mutex); NSURLSessionDataTask *task = [[NSURLSession sharedSession] dataTaskWithRequest:[[NSURLRequest alloc] initWithURL:_sourceImageURL] completionHandler:^(NSData *data, NSURLResponse *response, NSError *error) &#123; sourceImage = [UIImage imageWithData:data]; pthread_cond_signal(&amp;_signal); pthread_mutex_unlock(&amp;_mutex); &#125;]; [task resume]; pthread_cond_wait(&amp;_signal, &amp;_mutex); pthread_mutex_unlock(&amp;_mutex); &#125; return sourceImage;&#125; 当图片被渲染到 ImageView 的时候，利用 Instrument 查看并没有发生 CA::Render::copy_image 和 CA::Render::create_image_from_provider 的情况。 如何优化？FastImageCache是如何解决上述两个问题的？先看第一个问题，为何 Core Animation 在渲染之前要拷贝一份数据呢？在此之前，我们先看一些计算机系统的理论知识，等看完后再回头看看，答案便更加明朗了。我们都知道，图片说白了就是一段字节数据所组成的文件数据而已，也就是说我们把图片显示到界面上，不过是把一堆字节加载到 CPU 的寄存器当中，然后通过 GPU 将字节变成红(R)、绿(G)、蓝(B)的三原色的数组，然后通过界面显示出来(也就是我们所说的渲染)。所以，我们先了解一下，字节数据是如何通过内存加载到 CPU 的。 学过计算机操作系统的我们都知道，所有的字节数据都是通过总线来传送的，总线连接着 CPU 到主存，主存到磁盘等主要硬件设备的传输路线，而主要的传输单位就是字(word))，由于数字信号分为高频和低频，所以我们的计算机信号只有 0 和 1 两种来区分，所以我们采用了二进制的数据形式来表述数据，因此信号的量化精度一般以比特（bits）来衡量，这就是字节数据在总线中传输的本质。 而 64 位系统当中，字(word) 是 8 个字节的大小。内存的存储单元被称为块(Chunk))，而块的大小因硬件设备而定的，大多数文件系统都是基于块设备，即存取规定数据块的硬件抽象层。假如32位的文件系统中，高速缓存(Cache)以4个字节的块大小为传送到 CPU 当中，下图说明了 CPU 如何以4字节内存访问粒度访问4字节的数据查找： 如果我们们获取的数据为未对齐的4个字节，CPU 就会执行额外的工作去访问数据：加载两个字节块(Chunk)的数据，移出不需要的字节，然后将它们组合在一起。这个过程肯定会降低性能并浪费CPU周期，以便从内存中获取正确的数据。 所以我们存储数据的时候，需要进行 字节对齐(Byte Alignment) ，其实称为字节块对齐更为合适，也就是说我们所取的数据，都以上图第一种的形式在内存中读写，避免发生第二种情况，这样就能节省 CPU 周期，加快存取速度。 再回头看看当我们从内存中读取图片数据的时候，也是一堆的字节块，如果图像字节并没有经过如何处理，那么，就会出现以下情况： 当我们数据传输的时候，由字来传输，存储设备中读取内存却以块为单位, 所以从内存读取到的图像数据势必会带上其他”杂质字节”。所以便发生了——“通常情况”，但是 GPU 所需要的数据，是理想状态下的数据，因为这些”杂质字节”会影响图像生成。所以 Core Animation 就需要把”杂质字节”去除，然后变成我们的——“理想状态”。其实，不是 Core Animation 规定这么做，是我们接粗到图像处理的时候，都必须这么做，不然图像数据就乱了，只不过 Core Animation 帮我们封装了底层处理而已。通过我们学习到的知识，我们意识到，我们需要对图片的存入进行字节对齐。对于高速缓存(Cache)来说，存取都是以字节块的形式，而块的大小跟 CPU 的高速缓存存储器有关，ARMv7是 32 Byte，A9是 64 Byte，在 A9 下CoreAnimation 应该是按 64 Byte(也就是8个字，8Byte/字) 作为一块数据去读取、存储和渲染，让图像数据对齐64 Byte 就可以避免CoreAnimation再拷贝一份数据。能节约内存和进行copy的时间。(因为图片存入的时候已经对齐过了，获取的时候自然也是字节对齐的)， 如何字节块对齐避免 Core Animation 进行图像数据复制？以下是代码形式进行实操：计算图像所需字节大小123456/** FICImageTable.m */CGSize pixelSize = [_imageFormat pixelSize]; // 想要展示的图片大小NSInteger bytesPerPixel = [_imageFormat bytesPerPixel]; // 该图像个是中的字节每像素, 例如 FICImageFormatStyle32BitBGRA 为32位4个字节_imageRowLength = (NSInteger)FICByteAlignForCoreAnimation((size_t) (pixelSize.width * bytesPerPixel));_imageLength = _imageRowLength * (NSInteger)pixelSize.height; 通过 FICByteAlignForCoreAnimation 函数对图片数据进行字节对齐然后计算， 得到 _imageRowLength 图像每行的字节数, 图像所需字节 = 图像的高度 * _imageRowLength(字节块对齐的图像每行字节数)。 通过实际图像每行所需的字节进行字节块对齐123inline size_t FICByteAlignForCoreAnimation(size_t bytesPerRow) &#123; return FICByteAlign(bytesPerRow, 64); // 跟 CPU 的高速缓存器有关&#125; 让为 width 成为 alignment 的倍数计算1234inline size_t FICByteAlign(size_t width, size_t alignment) &#123; return ((width + (alignment - 1)) / alignment) * alignment;&#125; 创建Entry所对应的 Chunk，而 Chunk 是页对齐的1234// 设置每一个 entry 的字节长度，因为除了图像数据外，fastImageCache 还额外为图像添加了两个 UUID 的 32 个字节_entryLength = (NSInteger)FICByteAlign(_imageLength + sizeof(FICImageTableEntryMetadata), (size_t) [FICImageTable pageSize]);entryData = [[FICImageTableEntry alloc] initWithImageTableChunk:chunk bytes:mappedEntryAddress length:(size_t) _entryLength]; 为什么要进行页对齐？因为对于磁盘来讲，磁盘中的字节块大小就是页，因为分页就是磁盘和物理内存的存储方式，这样做就可以节省读取 entryData时CPU周期, 这是跟字节对齐一样的道理。 通过_imageRowLength来创建位图，由于图像字节块已经对齐, 避免 CA::Render::copy_image 图像数据的拷贝发生了.123456789101112// 创建 CGDataProviderRef 用于图像上下文创建，提供图像数据和数据结构的 Release 函数CGDataProviderRef dataProvider = CGDataProviderCreateWithData((__bridge_retained void *)entryData, [entryData bytes], [entryData imageLength], _FICReleaseImageData);CGSize pixelSize = [_imageFormat pixelSize]; // 想要展示的图片大小CGBitmapInfo bitmapInfo = [_imageFormat bitmapInfo]; // 位图数据的信息，例如是大小端，计算位数等NSInteger bitsPerComponent = [_imageFormat bitsPerComponent]; // 每个组成的位数，32位RGBA、RGB和8位Gray都为8bit，而16位的RGB为5bitNSInteger bitsPerPixel = [_imageFormat bytesPerPixel] * 8; // bit每个像素CGColorSpaceRef colorSpace = [_imageFormat isGrayscale] ? CGColorSpaceCreateDeviceGray() : CGColorSpaceCreateDeviceRGB(); CGImageRef imageRef = CGImageCreate((size_t) pixelSize.width, (size_t) pixelSize.height, (size_t) bitsPerComponent, (size_t) bitsPerPixel,(size_t) _imageRowLength, colorSpace, bitmapInfo, dataProvider, NULL, false, (CGColorRenderingIntent)0);CGDataProviderRelease(dataProvider);CGColorSpaceRelease(colorSpace); 文件读取，资源消耗？当我们从磁盘当中获取图像数据时，必须调用read()函数来从磁盘中读取图像字节数据，那么一起看看 read() 函数的调用过程: 图3-1 图3-1展示了当应用程序调用read()函数的时候： CPU 接受到中断信号，进入了内核模式。 内核模式中利用内核模式程序访问高速缓存(Cache)，查看高速缓存是否存在图像数据，如果又则返回，没有则继续访问物理内存。 内核模式程序读取物理内存，查看是否存在对应的物理页(由于磁盘跟物理内存的存储方式都是以分页的方式划分数据块的，通常64位系统为 4KB/页)，如果存在则将物理页数据，则返回相对应图像数据的物理页没有则发生异常行为(页错误)。 缺页异常处理程序访问磁盘，找到磁盘中对应的图像数据加载成磁盘页, 并磁盘页作为新页替换物理内存中的物理页，然后将物理页数据作为字节块缓存到高速缓存当中 异常处理程序发出中断信号将控制返回内核程序，内核程序再次加载高速缓存字节块返回放置内核缓冲区。 由于内核程序跟用户程序的内存地址空间是完全不同的，所以对于虚拟内存来讲，内核程序要降内核缓冲区中的数据字节进行一次拷贝，才能返回给用户程序.(PS: 用户程序跟内核程序的概念中，可能两者都为同一程序，只是由于CPU切换模式而转换，也有可能是两个不同的程序) CPU 读取内存页过程: 当然，上面的分析是针对逻辑层面跟硬件层面的讲解，实际上软件层面上，对于一次磁盘请求如下： 图3-2显示了 read 系统调用在核心空间中所要经历的层次模型。从图中看出, 对于磁盘的一次读请求: 首先经过虚拟文件系统层（vfs layer） 其次是具体的文件系统层（例如 ext2） 接下来是 cache 层（page cache 层） 通用块层（generic block layer） IO 调度层（I/O scheduler layer） 块设备驱动层（block device driver layer） 最后是物理块设备层（block device layer） 图3-2 read 系统调用在核心空间中的处理层次 (对于这部分目前先留个悬念，以后分享在详细讲解文集系统) 通过上面对read()函数的分析，我们知道从磁盘中读取一次文件的操作是非常繁碎而且非常消耗资源的(特别是大文件)，而且由于物理内存和高速缓存的资源是有限的，当我们不再访问图像数据的时候，图像数据就会被当做牺牲页换出物理内存和高速缓存，当我们应用程序后面再次read()访问的时候，还得再次重新走上述流程。那么这个时候我们可以怎么优化来加快我们对图片的IO呢？ 如何优化？对于我们iOS这种封闭系统来讲，优化手段其实很有限，因为我们不能直接操作内核，但是在是不是就无法优化呢？而操作系统为我们提供了一个用户级的内核函数，mmap/ummap，这是一个实现内存映射做法，那么内存映射能为我们读写文件的操作带来什么？答案就是优化了上述流程的 1 和 6 中所产生的内存拷贝过程，我们首先来看看内存映射是什么。 操作系统通过将一个虚拟内存区域与一个磁盘上的对象(object)关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射(memory mapping). 下图展示了内存映射的做法： 下图展示了内存映射区域在进程中的位置： 当磁盘文件通过内存映射到应用程序的时候，是直接跟用户空间的地址相关联的，也就是说当我们读取磁盘文件数据的时候，CPU 不用在切换用户空间和内核空间，随之字节拷贝也不会再发生，所有读取操作都能在用户空间中进行。 好了，说了这么多，具体做法怎么做呢？在 FastImageCache 当中，创建 Chunk 直接文件中的对一个 Chunk 内存区域部分进行内存映射：123456789101112131415161718192021// FICImageTableChunk.m- (instancetype)initWithFileDescriptor:(int)fileDescriptor index:(NSInteger)index length:(size_t)length &#123; self = [super init]; if (self != nil) &#123; _index = index; _length = length; _fileOffset = _index * _length; // 通过内存映射设置为共享内存文件 _bytes = mmap(NULL, _length, (PROT_READ|PROT_WRITE), (MAP_FILE|MAP_SHARED), fileDescriptor, _fileOffset); if (_bytes == MAP_FAILED) &#123; NSLog(@"Failed to map chunk. errno=%d", errno); _bytes = NULL; self = nil; &#125; &#125; return self;&#125; 这里就有一个疑问了，通过FastImageCache 架构分析文章中知道，一个图片文件应该对应为一个Entry才对呀，为什么现在内存映射要映射Chunk呢？因为内存映射文件越大越有效果呀，不然小数据通过read()函数直接进入内核拷贝字节这种做法就跟内存映射没有对比了。 为了让映射文件越大， FastImageCache 甚至直接在存储图片的时候就直接降图片解码了：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970- (void)setEntryForEntityUUID:(NSString *)entityUUID sourceImageUUID:(NSString *)sourceImageUUID imageDrawingBlock:(FICEntityImageDrawingBlock)imageDrawingBlock &#123; if (entityUUID != nil &amp;&amp; sourceImageUUID != nil &amp;&amp; imageDrawingBlock != NULL) &#123; [_lock lock]; // 递归锁 // 创建 Entry NSInteger newEntryIndex = [self _indexOfEntryForEntityUUID:entityUUID]; if (newEntryIndex == NSNotFound) &#123; newEntryIndex = [self _nextEntryIndex]; if (newEntryIndex &gt;= _entryCount) &#123; // Determine how many chunks we need to support new entry index. // Number of entries should always be a multiple of _entriesPerChunk NSInteger numberOfEntriesRequired = newEntryIndex + 1; NSInteger newChunkCount = _entriesPerChunk &gt; 0 ? ((numberOfEntriesRequired + _entriesPerChunk - 1) / _entriesPerChunk) : 0; NSInteger newEntryCount = newChunkCount * _entriesPerChunk; [self _setEntryCount:newEntryCount]; &#125; &#125; if (newEntryIndex &lt; _entryCount) &#123; CGSize pixelSize = [_imageFormat pixelSize]; CGBitmapInfo bitmapInfo = [_imageFormat bitmapInfo]; CGColorSpaceRef colorSpace = [_imageFormat isGrayscale] ? CGColorSpaceCreateDeviceGray() : CGColorSpaceCreateDeviceRGB(); NSInteger bitsPerComponent = [_imageFormat bitsPerComponent]; // Create context whose backing store *is* the mapped file data FICImageTableEntry *entryData = [self _entryDataAtIndex:newEntryIndex]; // 创建内存映射区域 if (entryData != nil) &#123; [entryData setEntityUUIDBytes:FICUUIDBytesWithString(entityUUID)]; [entryData setSourceImageUUIDBytes:FICUUIDBytesWithString(sourceImageUUID)]; // Update our book-keeping _indexMap[entityUUID] = @((NSUInteger) newEntryIndex); [_occupiedIndexes addIndex:(NSUInteger) newEntryIndex]; _sourceImageMap[entityUUID] = sourceImageUUID; // 用于内存最近使用策略来装载和释放内存 [self _entryWasAccessedWithEntityUUID:entityUUID]; [self saveMetadata]; // Unique, unchanging pointer for this entry's index NSNumber *indexNumber = [self _numberForEntryAtIndex:newEntryIndex]; // Relinquish the image table lock before calling potentially slow imageDrawingBlock to unblock other FIC operations [_lock unlock]; // 利用创建位图，将图图象数据draw到位图当中，然后再保存位图字节数据 CGContextRef context = CGBitmapContextCreate([entryData bytes], (size_t) pixelSize.width, (size_t) pixelSize.height, (size_t) bitsPerComponent, (size_t) _imageRowLength, colorSpace, bitmapInfo); CGContextTranslateCTM(context, 0, pixelSize.height); CGContextScaleCTM(context, _screenScale, -_screenScale); @synchronized(indexNumber) &#123; // Call drawing block to allow client to draw into the context // 解码 imageDrawingBlock(context, [_imageFormat imageSize]); CGContextRelease(context); // Write the data back to the filesystem [entryData flush]; &#125; &#125; else &#123; [_lock unlock]; &#125; CGColorSpaceRelease(colorSpace); &#125; else &#123; [_lock unlock]; &#125; &#125;&#125; 这里涉及到了递归锁，主要是防止多次调用lock造成死锁，有机会再次跟大家分享递归锁的神奇用法。 代码中-_entryDataAtIndex方法便创建了Chunk，但此时Chunk并没有数据，只是做了一个文件的映射区域.利用-_indexOfEntryForEntityUUID创建了Entry, 分配了图像所需的字节和UUID等metaData所需的字节内存空间。然后我们使用-CGBitmapContextCreate利用内存空间创建位图，通过-imageDrawingBlock将图片字节全部draw到位图，然后通过Entry flush 就图像数据同步到磁盘当中, 这就完成了图片的存储了。 存在的问题但是内存映射是不是就没有缺陷呢？通过上文学习我们知道，内存映射是直接对应这虚拟内存区域的，也就是说是占用这我们虚拟内存的地址空间的，而且是一块常驻内存，那么当映射内存非常大的时候，甚至会影响我们程序的堆内存创建反而导致性能更差。所以 FastImageCahce 中甚至给Entry做了内存限制，一个Entry只能存储两M的数据. 1234NSInteger goalChunkLength = 2 * (1024 * 1024);NSInteger goalEntriesPerChunk = goalChunkLength / _entryLength;_entriesPerChunk = (NSUInteger) MAX(4, goalEntriesPerChunk); // 最少也要存在 4Entry/Chunk_chunkLength = (size_t)(_entryLength * _entriesPerChunk); // Chunk 的内存字节大小 实际大小要跟着图像的大小改变，但是跟 2M 不会相差太多。 未完待续…(后续学到新方法，会持续更新) 通过上述方法，就能有效的加快我们图片的文件IO，特别当前我们的女性用户，手机里面有几十G图图片，当我们要做一个图片相册的精美应用的时候，这些性能便不可忽视了。根据摩尔定律，计算机性能约每隔18-24个月便会增加一倍，性能也将提升一倍，但是用户的要求和使用方式也会随着时间不断提高的！所以，平常培养对计算机原理的深入理解，才能写出高性能的代码，才不会在面对高并发高内存的情况下素手无策。 参考文献：《Linux驱动mmap内存映射》]]></content>
      <categories>
        <category>计算机系统</category>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅读CASPP——进程篇]]></title>
    <url>%2F2018%2F04%2F03%2Fprocess-from-csapp%2F</url>
    <content type="text"><![CDATA[在现代系统上运行一个程序时，我们会得到一个假象，就好像我们的程序是系统中当前运行的唯一的程序一样。我们的程序好像是独立地使用处理器和内存。处理器就好像是系统中当前运行的唯一程序一样。我们的程序就好像是独占地使用处理器和内存。处理器就好像是无间断地一条一条地执行我们程序中的指令。最后，我们程序中的代码和数据好像是系统内存唯一对象。而这些假象都是通过进程的概念提供给我们的。 未完待续… 学前疑问: 什么是进程？为什么需要进程？ 进程的组成部分？ 什么是进程的上下文？ 什么是上下文切换，为什么需要上下文切换? 模式切换？上下文切换？ 什么是 I/O 操操? 进程的切换的详细过程. 什么是进程?进程的经典定义就是一个执行中程序的实例。当我们使用 shell 输入命令行 ‘./helloWorld.out’ 以运行 helloWorld 可执行文件的时候，shell 就会创建一个新的进程，然后再这个新进程的上下文中运行这个可执行文件。也可以说进程、线程、异常处理程序等是一个逻辑。 进程的地址空间进程为每个程序提供给它自己的私有空间，这就制造了进程独占地使用系统地址空间。可以看出一个程序的内存空间分了内核空间和用户空间，而用户空间是无法访问内核空间的地址的。如果一个用户进程必须通过系统调用接口(例如read，write 函数)间接地访问内核代码和数据。虚拟地址基址通过一下命令查看一下 Mac 系统的程序入口：123456789101112131415➜ abson_blog git:(master) ✗ xcrun size -x -l -m ~/Desktop/learnCpp/main.outSegment __PAGEZERO: 0x100000000 (vmaddr 0x0 fileoff 0)Segment __TEXT: 0x1000 (vmaddr 0x100000000 fileoff 0) Section __text: 0x34 (addr 0x100000f50 offset 3920) Section __stubs: 0x6 (addr 0x100000f84 offset 3972) Section __stub_helper: 0x1a (addr 0x100000f8c offset 3980) Section __cstring: 0x4 (addr 0x100000fa6 offset 4006) Section __unwind_info: 0x48 (addr 0x100000fac offset 4012) total 0xa0Segment __DATA: 0x1000 (vmaddr 0x100001000 fileoff 4096) Section __nl_symbol_ptr: 0x10 (addr 0x100001000 offset 4096) Section __la_symbol_ptr: 0x8 (addr 0x100001010 offset 4112) total 0x18Segment __LINKEDIT: 0x1000 (vmaddr 0x100002000 fileoff 8192)total 0x100003000i 可以看到 Mac 的程序入口, 也就是说程序加载器把可执行文件加载到内存的虚拟地址基址是 0x100000000。 上图展示了程序的地址空间分配图，在 Linux 下，一个进程的地址空间一般为4GB(内核地址空间1G，用户地址空间3GB)，这里所说的地址空间都为虚拟内存地址(关于什么是虚拟内存，查看阅读CSAPP——虚拟内存篇)。 系统调用系统调用在类Unix系统中指的是活跃的进程对内核所提供的服务进行请求。例如输入/输出(I/O和进程创建)。 I/O 操作I/O 可以被定义为任何信息流入或流出 CPU 与主内存（RAM）。也就是说，一台电脑的 CPU和内存与该电脑的用户（通过键盘或鼠标）、存储设备（硬盘或磁盘驱动）还有其他电脑的任何交流都是 I/O。 进程的上下文内核为每个进程维持着一个上下文，上下文由一些对象的值组成，这些对象包括通用目的的寄存器，浮点寄存器，程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构(比如描述地址空间的页表，包含有关当前进程信息进程表，以及包含进程已打开文件的信息的文件表)。简而言之，进程的上下文就是保存了进程的状态和堆栈内存的数据结构等等。 进程的上下文切换当某些时刻，例如读写文件等操作时进程发生了阻塞的行为，内核中的调度器(代码实现, 也就是说上下文切换只能发生在内核模式中),会让当前进程A休眠，切换到另外一个进程B，这个时候就会发生以下三步操作： 保存进程A的所有状体，也就是进程的上下文。 恢复进程B被保存上下文。 将控制传递给进程B。 这三个步骤就称为上下文切换,也可以说是进程切换,。当然，即使是系统调用没有发生阻塞时，内核也可以决定执行上下文切换。例如中断行为，系统会有一个周期性的中断定时器，每隔一段时间当定时器发生中断时，内核就能判断当前进程运行的时间足够长，并切换到一个新的进程。(这也是多任务并发的思想，叫做时间分片)。 用户模式和内核模式进程切换必须在操作系统内核模式下完成，这就需要模式切换，模式切换又称为CPU状体切换。用户模式和内核模式一般被称为用户态和内核态。是 CPU 提供给的一种机制，是 CPU 的一种模式状态,用于限制一个应用可以执行的指令以及它可以访问的地址空间范围。 用户态这样做可以将每个用户进程都能独立开来,使其无法更改属于其他应用程序的数据。每个应用程序都孤立运行，如果一个应用程序损坏，则损坏会限制到该应用程序。其他应用程序和操作系统不会受该损坏的影响。 内核态下运行的所有代码都共享单个虚拟地址空间, 进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置。但这表示内核态进程未从其他进程和操作系统自身独立开来，如果内核态进程意外写入错误的虚拟地址，则属于操作系统或其他驱动程序的数据可能会受到损坏。注意：这是一种模式切换，而不是上下文切换，因为它不一定引起进程状态的转换，在大多数情况下，也不一定引起进程切换。例如，运行一个进程时间片，让进程停止运行一段时间后恢复。这种状态下进程只是引发了中断后 CPU 进入内核模式并执行处理程序，时间片过后处理程序就恢复被进程的状态信息，CPU 重新进入用户模式。 整个操作系统分为两层：用户态和内核态，这种分层的架构极大地提高了资源管理的可扩展性和灵活性，而且方便用户对资源的调用和集中式的管理，带来一定的安全性。比如说我们应用程序要使用打印机打印文字，如果在没有内核模式管理的情况下，每个应用程序都可以争抢打印资源，那么打印出来的顺序就是乱的了，所以这些共享资源就必须通过内核模式的统一管理，以下这幅图详尽的分析了内核所做的事情: 很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。比如C函数库中的内存分配函数malloc()，它具体是使用sbrk()系统调用来分配内存，当malloc调用sbrk()的时候就涉及一次从用户态到内核态的切换，类似的函数还有printf()，调用的是wirte()系统调用来输出字符串，等等。 何时切换？到底在什么情况下会发生从用户态到内核态的切换，一般存在以下三种情况： 当然就是系统调用：原因如上的分析。 异常事件： 当CPU正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。 外围设备的中断：当外围设备完成用户的请求操作后，会像CPU发出中断信号，此时，CPU就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。 从触发方式和效果上来看，这三种切换方式是完全一样的，都相当于是执行了一个中断响应的过程。但是从触发的对象来看，系统调用是进程主动请求切换的，而异常和硬中断则是被动的。系统调用一般被称为软中断。 上图中看出，这种模式切换不一定发生在两个不同的进程当中，极有可能在单个进程中切换，并没有涉及到进程的上下文切换。所以模式切换跟上下文切换有着本质的区别。 如何切换？ 用户模式 ——&gt; 内核模式：中断/异常/系统调用 (正向模式切换) CPU模式转为内核模式 保存当前进程的PC/PSW值到核心栈 转向中断/异常/系统调用处理程程序。 处理中断/异常 内核模式 ——&gt; 用户模式：OS执行终端返回指令 (逆向模式切换) 恢复被中断进程的现场信息。 从待运行进程核心栈中弹出PSW/PC值。 CPU模式转为用户模式。 在正向模式切换，涉及到了用户空间的进程需要传递变量、参数等值给内核，内核态运行的时候也要保存用户进程的一些寄存器值、变量等，但是用户空间跟内核空间是两个地址环境完全不同的环境，也就是说，这些参数和变量都需要进行内存拷贝，那么这里就涉及到了部分开销。对于逆向模式也是反之亦然的道理。]]></content>
      <categories>
        <category>计算机系统</category>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>笔记与理解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阅读CSAPP——虚拟内存篇]]></title>
    <url>%2F2018%2F04%2F03%2Fvirtual-memory-from-csapp%2F</url>
    <content type="text"><![CDATA[未完待续… 学前疑问： 什么是虚拟内存，为什么需要虚拟内存？ 虚拟内存与我们所熟悉的物理内存(主存, 高速缓存)有什么关系? 一个虚拟内存地址是如何访问物理内存并获取所需的内存字节? 程序的内存分布状态，为什么需要如此分布？ 什么是内存映射，内存映射能为我们带来什么好处(利用内存映射能做什么)? 堆内存(动态内存)的的分配、分配所带来的问题和如何有效的利用动态内存？ 为什么需要虚拟内为什么需要虚拟内存? 为什么内存要分页？ 假设内存是连续分配的（也就是程序在物理内存上是连续的） 进程A进来，向os申请了200的内存空间，于是os把0~199分配给A 进程B进来，向os申请了5的内存空间，os把200~204分配给它 进程C进来，向os申请了100的内存空间，os把205~304分配给它 这个时候进程B运行完了，把200~204还给os 但是很长时间以后，只要系统中的出现的进程的大小&gt;5的话，200~204这段空间都不会被分配出去（只要A和C不退出）。 过了一段更长的时间，内存中就会出现许许多多200~204这样不能被利用的碎片…… 而分页机制让程序可以在逻辑上连续、物理上离散。也就是说在一段连续的物理内存上，可能0~4（这个值取决于页面的大小）属于A，而5~9属于B，10~14属于C，从而保证任何一个“内存片段”都可以被分配出去。 虚拟内存、虚拟页、虚拟地址 虚拟内存大小要看计算机系统的位数。 虚拟页大小是可以设置的，在Unix上一般大小为 4kb。 虚拟地址的数量是根据虚拟页大小和虚拟内存大小确定的，因为一个虚拟地址对应一个虚拟页，虚拟地址分为两部分 VPN + VPO ，虚拟页号 + 虚拟页偏移量，虚拟页号也就是每个页特有的编号，就像一个背包的商品编号9527一样; 虚拟页偏移量也就是页大小, 标识这这个页到底装了多少“有效数据”，就像这个9527的背包能装多少重量的物品一样。 内存映射 Linux 通过将一个虚拟内存区域与一个磁盘上的对象(object)关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射(memory mapping).所以内存映射也叫做内存映射文件。 虚拟内存区域可以映射到两种类型的对象中的一种： Linux 文件系统中的普通文件 匿名文件 区别：普通文件是磁盘上的一个文件，被分成页大小的片，每一片包含一个虚拟内存页面的初始内容，这些页面是按需调度到物理内存当中的。 匿名文件由内核创建，存在于物理内存当中，并不存在于磁盘。 用户函数 mmap 使用内存映射mmap/umap 是创建/删除虚拟内存区域的函数。例如 .bbs、栈、堆 等等就是不同的虚拟内存区域。12 内存映射的好处 页命中和缺页 同任何缓存一样，虚拟内存系统必须有某种方法判断一个虚拟页是否缓存在DRAM中的某个地方。如果是，系统必须确定这个虚拟页放在哪个物理页中。如果不命中，系统必须判断这个虚拟页放在磁盘哪个位置上，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。 页表（PTE）：上面这些判断缓存的功能是由软硬联合提供的，包括操作系统软件，MMU（内存管理单元）中的地址复议硬件和一个存放在物理内存中叫做页面的数据结构，页表将许你夜映射到物理页。 每次地址翻译硬件将一个虚拟地址转换成物理地址时，就会读取页表。操作系统负责维护页表的内存，以及磁盘与DRAM之间来回传输页。 页命中： 缺页：DRAM 缓存不命中 上图流程中如果 VP4 已经被修改，那么内核将会将它复制回磁盘。 地址翻译 地址翻译概念流程： 图中可以看出一项 PTE 是一个 有效位+物理页号/磁盘地址 的结构。 假设页命中：虚拟地址通过 PTE 得知有效位为1，得到了物理页号PPN，物理页偏移量 == 虚拟页偏移量，通过 物理页号+虚拟地址偏移量 = 物理地址了，通过物理地址可以直接到物理内存中（DRAM）读取字节块。 假设页缺失：虚拟地址通过 PTE 得知有效位为0，得到了磁盘地址，然后触发页缺失异常，系统通过磁盘地址到磁盘中读取字节块，然后把字节块分页加载到物理内存当中，需要的时候选取物理内存中牺牲页交换，完成后，再次通知系统重新走虚拟地址获取物理页号的流程（跟上面页命中一样了）。PS：页表中页命中的PTE带着物理页号，缺页的PTE带:着磁盘地址。 VA：虚拟地址 （virtual address）。PTEA：页表条目地址（page table entry address）。PTE：页表条目（page table entry）。PA：物理地址（physics address）。 一个进程的虚拟内存布局虚拟内存中的区域划分 进程内存区域结构体: 动态内存分配器动态内存分配器 malloc 函数是维护着一个进程的虚拟内存区域（堆）的内存分配。 动态内存分配器有两种基本风格： 显式内存分期器，手动分配/释放内存，例如C语言标准库 malloc/free 函数。 隐式分配器，分配器主动检测已分配块何时不再被程序使用并进行释放，例如 Java 的 PS: 动态内存分配（Dynamic memory allocation）又称为堆内存分配 堆的内存碎片 导致堆利用率很低的主要原因是一种称为碎片(fragmentation)的现象。碎片分为两种： 内部碎片 外部碎片 内部碎片：这个跟分配器的实现有关，例如分配器可能要增加块的大小来满足内存对齐约束条件，就会产生额外的块。（这个额外的块就是碎片） 外部碎片：这种情况发生在堆中没有一个独立的空闲块足够大来满足一个分配请求的时候发生，程序主动向内核请求额外的虚拟内存来满足这个请求。这样导致了许多分散的空闲块无法分配。（这些空闲块就是碎片） 如何提高内存利用率（减少内存碎片） 空闲块的处理：如何记录空闲块 放置: 如何选择一个合适的空闲块放置一个新分配的块 分割：将一个新分配的块放置到某个空闲块之后，如何处理空闲块中的剩余部分 合并：如何处理一个刚刚释放的块 空闲块的处理使用隐式空闲链表这种数据结构。 放置 首次适配 下一次适配 最佳适配 分页跟分块的 分页：指的是内存分页，例如虚拟内存被分割成虚拟页、物理内存被分割成物理页，磁盘内存被分割成磁盘页。目的是为了减少物理内存的碎片产生，让程序逻辑上是连续的(虚拟内存)，物理上是离散的(物理内存)。 分块： 堆块的格式 内存抖动 当分配器释放一个已分配的块时，分配器使用了空闲块的立即合并策略，也就是合并所有相邻的空闲块。这种模式导致了一个问题：如果有大量这些小内存块申请的请求和释放，块就会反复合并，然后马上分割，这样就产生了一种形式的抖动。]]></content>
      <categories>
        <category>计算机系统</category>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Posix多线程之旅——生产者-消费者]]></title>
    <url>%2F2018%2F04%2F03%2Fposix-producer-consumer-problem%2F</url>
    <content type="text"><![CDATA[生产者消费者问题（英语：Producer-consumer problem），也称有限缓冲问题（英语：Bounded-buffer problem），是一个多线程同步问题的经典案例。该问题描述了共享固定大小缓冲区的两个线程——即所谓的“生产者”和“消费者”——在实际运行时会发生的问题。生产者的主要作用是生成一定量的数据放到缓冲区中，然后重复此过程。与此同时，消费者也在缓冲区消耗这些数据。该问题的关键就是要保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中空时消耗数据。 但是在 leveldb 中有这么一段代码，很好的写出了一个后台线程传入事件异步并发执行执行。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#include &lt;iostream&gt;#include &lt;deque&gt;#include &lt;unistd.h&gt;class PosixEnv&#123;public: PosixEnv() : started_bgthread_(false) &#123; PthreadCall("mutex_init", pthread_mutex_init(&amp;mu_, NULL)); PthreadCall("cvar_init", pthread_cond_init(&amp;bgsignal_, NULL)); &#125; void Schedule(void(*function)(void*), void* arg) &#123; PthreadCall("lock", pthread_mutex_lock(&amp;mu_)); // Start background thread if necessary if (!started_bgthread_) &#123; started_bgthread_ = true; PthreadCall( "create thread", pthread_create(&amp;bgthread_, NULL, &amp;PosixEnv::BGThreadWrapper, this)); &#125; if (queue_.empty()) &#123; // 如果当前队列为空，那么后台线程此时可能为信号等待状态，激活一个等待该条件的线程 PthreadCall("signal", pthread_cond_signal(&amp;bgsignal_)); &#125; BGItem item = BGItem(); item.arg = arg; item.function = function; queue_.push_back(item); // 当 unlock 后，pthread_cond_wait 获取到条件信号和锁，就会执行之后的代码 PthreadCall("unlock", pthread_mutex_unlock(&amp;mu_)); &#125; static void* BGThreadWrapper(void* arg) &#123; reinterpret_cast&lt;PosixEnv*&gt;(arg)-&gt;BGThread(); return NULL; &#125;#pragma clang diagnostic push#pragma clang diagnostic ignored "-Wmissing-noreturn" void* BGThread() &#123; while (true) &#123; // Wait until there is an item that is ready to run PthreadCall("lock", pthread_mutex_lock(&amp;mu_));// 这个mutex主要是用来保证 pthread_cond_wait的并发性 while (queue_.empty()) &#123; // 等待条件信号，并将锁交出去，当获取到信号量 PthreadCall("wait", pthread_cond_wait(&amp;bgsignal_, &amp;mu_)); // pthread_cond_wait 会先解除之前的 pthread_mutex_lock 锁定的 mtx，然后阻塞在等待对列里休眠， // 直到再次被唤醒（大多数情况下是等待的条件成立而被唤醒，唤醒后，该进程会先锁定先 pthread_mutex_lock(&amp;mtx); &#125; void (*function)(void*) = queue_.front().function; void* arg = queue_.front().arg; queue_.pop_front(); PthreadCall("unlock", pthread_mutex_unlock(&amp;mu_)); // 异步并行执行方法，如果将这句代码放在 unlock 之前那么就是异步串行了 (*function)(arg); &#125; &#125;#pragma clang diagnostic popprivate: void PthreadCall(const char* label, int result) &#123; std::cout &lt;&lt; label &lt;&lt; std::endl; if (result != 0) &#123; fprintf(stderr, "pthread %s: %s\n", label, strerror(result)); abort(); &#125; &#125; pthread_mutex_t mu_; pthread_cond_t bgsignal_; pthread_t bgthread_; bool started_bgthread_; struct BGItem &#123; void* arg; void (*function)(void*); &#125;; typedef std::deque&lt;BGItem&gt; BGQueue; BGQueue queue_;&#125;;void speak(void* pstr)&#123; std::string* str = reinterpret_cast&lt;std::string*&gt;(pstr); printf("我要说话啦：%s\n", str-&gt;c_str());&#125;int main(int argc, const char * argv[]) &#123; std::string str("哇哈哈哈啊哈哈哈啊哈哈"); std::string str2("你的豆腐的的地方水电费违反诶我去翁"); PosixEnv env = PosixEnv(); env.Schedule(&amp;speak, &amp;str); sleep(10); env.Schedule(&amp;speak, &amp;str2); sleep(5); return 0;&#125; 上面例子，把所有的事件模型包装成一个struct BGItem 的结构体，而通过 BGQueue 对消息队列进行处理，这里没有用到延时执行的消息队列，也没有优先队列的处理，只是一个简单的生产者——消费者的模型。通过创建一个工作线程 bgthread_ 来开启线程运作，通过信号量 pthread_cond_wait 和 pthread_cond_signal 来进行控制工作线程的阻塞和运作。该例子中，主线程负责生成事件模型，而工作线程负责消费处理事件模型，而消息队列，就是我们所说的缓冲区了。]]></content>
      <categories>
        <category>源码分析</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>Posix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Unix 常用工具命令笔记]]></title>
    <url>%2F2018%2F04%2F03%2FUnix-common-commandline%2F</url>
    <content type="text"><![CDATA[一些Unix/Linux 和 Mac/iOS 的命令行工具，用于学习、测试 iOS 开发和后端开发的常用命令，持续更新中… gnu套装工具gcc 编译器生成目标文件 （二进制机器代码）1gcc -c 生成可执行文件 （链接器重定位）1gcc -o 打开gcc所有警告1gcc -Wall ld 链接器将多个目标文件合并成一个目标文件1ld -r cat (文本文件查看和连接工具)一次显示整个文件1cat 文件名 创建一个文件1cat &gt; 文件名 将几个文件合并成一个文件1cat 文件名1 文件名2 &gt; 文件名3 更多的使用参考 ar (压缩工具——用于静态库)查看静态库文件包含了那些目标文件1ar -t libc.a 解压静态库文件，得到对目标文件进行编号和索引的 __.SYMDEF文件1ar -x libc.a 将目标文件打包成静态链接库1ar crv libmylib.a my_print.o my_match.o 删除静态链接库中的某个目标文件1ar -d lib.a my_print.o 要替换或添加新成员到库中1ar -v -r lib.a strlen.o strcat.o 1-v : 将建立新库的详细的逐个文件的描述写至标准输出。当和 -t 标志一起使用时，它给出类似于 ls -l 命令给出的长列表。当和 -x 标志一起使用时，它在每个文件前加一个名称。当和 -h 标志一起使用，它列出成员名称和更新的修改时间。 grep (文本搜索工具)搜索 services 文件内的 telnet 字段1grep telnet /etc/services netstat (内核中访问网络及相关信息的程序)查看本机的路由表1netstat -nr 显示所有socket，包括正在监听的1netstat -a 显示协议名查看某协议使用情况 netstat -p 协议名1netstat -p tcp arp用于查看高速缓存中的所有项目1arp -a 或1arp -g dns 查看DNS服务器地址 这个文件内存放DNS服务器的IP地址1cat /etc/resolv.conf 其中的两个IP地址分别是首选DNS服务器地址和备选DNS服务器地址。文件中的注释语句“Generated by Network Manager”告诉我们，这两个DNS服务器地址是由网络管理程序写入的。 将查询传递给DNS服务器，并显示返回的结果1host baidu.com tcpdump lipo 因为苹果在 mac 上使用的静态库都是一些通过多个不同架构的静态库合成的压缩文件格式，所有有了 lipo 工具来操作这个压缩文件 查看 mac os系统中静态库中包含了那些架构1lipo -info lib.a 解压出指定架构的静态库1lipo lib.a -thin armv7 -output lib-armv7.a 合并模拟器库文件和真机库文件1lipo -create -output lib.a lib-armv6.a lib-i386.a dwarfdump (用于查看 dSYM 符号集合文件) * 为文件名 查看 .dSYM 符号文件中的所有符号1dwarfdump SocialDevApp.app.dSYM &gt; text 查看地址为 0x0024d6a5 所对应的符号1dwarfdump --lookup=0x0024d6a5 SocialDevApp.app.dSYM : 查看 .dSYM 文件 UUID 是否跟 .crash 文件是否一致1dwarfdump --uuid /*.app.dSYM symbolicatecrash 符号化 .crash 文件首先要找到 symbolicatec 这个 shell 在哪里，进入 xcode.app, 使用如下命令1find . -name symbolicatecrash 符号化 .crash 1./symbolicatecrash /*.crash /*.app.dSYM &gt; /*.crash 如果发生错误1&quot;DEVELOPER_DIR&quot; is not defined at ./symbolicatecrash line 69. 使用如下1export DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer xcode 中所有 dSYM 文件的位置1~/Library/Developer/Xcode/Archives objdump 用于查看 目标文件(.o) 或 可 执行的目标文件(.out) 构成的 GCC 工具 反汇编目标文件1objdump -d main.o &gt; text 显示符号表入口1objdump -t main.o 尽可能反汇编出源代码1objdump -S main.o file用于查看文件编码的命令 12345678file info.plist输出：info.plist: Apple binary property listfile SsjjCoreSdk输出：SsjjCoreSdk: Mach-O universal binary with 2 architectures: [arm_v7: current ar archive] [arm64]SsjjCoreSdk (for architecture armv7): current ar archiveSsjjCoreSdk (for architecture arm64): current ar archive lsof (一切皆文件) lsof（list open files）是一个查看当前系统文件的工具。在Unix 环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。 查看系统中端口占用情况1lsof -i 查看某一端口的占用情况：lsof -i:端口号1lsof -i:21 查找某个文件相关的进程：lsof 文件名1lsof /bin/bash 更多使用 ps (查看进程)显示所有进程信息1ps -A ps 与grep 组合使用，查找特定进程1ps -ef|grep ssh 列出目前所有的正在内存中的程序1ps aux otool (Mac上的objdump)反汇编 mach-o 目标文件1otool -tV main.out]]></content>
      <tags>
        <tag>Unix/Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出 GCD 线程使用]]></title>
    <url>%2F2018%2F04%2F02%2Fgrand-central-dispatch-introduction%2F</url>
    <content type="text"><![CDATA[串行与并行同步和异步针对的是线程队列，所谓的线程队列可以理解为一组线程的数组。 串行队列：队列中是事件有序执行，遵循 FIFO（first in first out）的原则，先进入队列的事件先执行。 串行队列创建：123dispatch_queue_t queue = dispatch_queue_create("com.queue.serial", DISPATCH_QUEUE_SERIAL);dispatch_get_main_queue() // 主队列，也是串行队列 并行队列并行队列中的事件在逻辑上是一起执行的，但是这是要根据机器 CPU 的情况而定，在 C++ 线程库中，std::thread::hardware_concurrency() 能获取到当前机器最大能并发的线程数量，iPhone6P 中为 2，也就是说最大同时能处理两个并发线程任务，其他后面添加的任务都得等待两个任务中的其中一个执行完了，才可以执行。 123dispatch_queue_t queue = dispatch_queue_create("com.queue.concurrent", DISPATCH_QUEUE_CONCURRENT);dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); // 全局并发队列 同步和异步同步和异步针对的是线程，那么什么是同步线程，什么是异步线程。 同步线程：阻塞当前线程，要等待同步线程内的任务执行完了并且返回以后，才可以继续执行被阻塞线程的事件。 同步线程创建：1dispatch_sync(queue, block); 异步线程：不阻塞当前线程，等当前线程完成时间片（完成当前事件）切换后再执行异步线程。 异步线程创建：1dispatch_async(queue, block); 线程问题主线程中的死锁12345NSLog(@"1");dispatch_sync(dispatch_get_main_queue(), ^()&#123; NSLog(@"2");&#125;);NSLog(@"3"); 输出：1 如果上面代码是在主线程当中执行的，那么就会造成我们的死锁问题，注意是主线程当中，后面我们还有一个测试说明。假定上面代码为主线程中执行的代码，如果不造成死锁的情况是输出应该是 1，2，3，但现在事件只执行了 1，那么死锁就很明显了，我们现在对它进行分析。 dispatch_sync 同步线程，将当前线程阻塞，先执行block（@”2”) 然后解放线程dispatch_get_main_queue 主线程队列，也可以叫做串行队列，将 dispatch_sync 同步线程放到队列后，先执行 ( @”3”) 再执行同步线程，遵循 FIFO 的原则。当时因为 dispatch_sync 是在主线程创建的，所以主线程被阻塞，主线程的事件(@”3”) 要等待 dispatch_sync 的 block 执行完后才能执行所以事件(@”3”)无法执行，事件(@”2”)更无法执行，相互等待造成死锁。 dispatch_sync(dispatch_get_main_queue(), block)是否一定会造成死锁呢？上面问题如果并不是放在主线程中有会怎么样？ 12345678910NSLog(@"1");dispatch_queue_t queue = dispatch_queue_create("com.queue.concurrent", DISPATCH_QUEUE_CONCURRENT);dispatch_async(queue), ^()&#123; NSLog(@"2"); dispatch_sync(dispatch_get_main_queue(), ^()&#123; NSLog(@"3"); &#125;); NSLog(@"4");&#125;);NSLog(@"5"); 输出: 1，5，2，3，4 输出中，可以看得出所有事件全部都执行完成，没有造成死锁，但是明明使用了 dispatch_sync(dispatch_get_main_queue(), block);这个经常被说成会造成死锁的方法，但是为什么这里没有造成死锁呢，我们来分析一下。 dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT,block) 中， dispatch_async 异步线程，将其放在了 dispatch_get_global_queue 全局队列，也可以叫并行队列中，主线程不用等待异步 dispatch_async 内的事件（block）执行完成，所以直接执行了事件(@“1”)和事件(@”5”)。当线程时间片切换出来，异步线程内的事件(block)便开始执行了，所以事件(@”2”) 便执行了。当运行到 dispatch_sync(dispatch_get_main_queue(),block) 中，dispatch_sync 阻塞当前线程，细想一下，当前线程是一个异步线程并不是主线程，事件(@”4”)又是在这个异步线程中的事件，所以要等待 dispatch_sync 同步线程内的事件执行完了，才可以执行。同步线程放在 dispatch_get_main_queue 主线程队列中，主线程队列同时也是一个串行队列，所以事件(@”3”) 一定会在事件@(“1”)和事件(@”5”)之后，当执行完事件(@”3”)便可以执行事件(@”4”)了。 上面例子说明一件事，dispatch_async 同步线程会阻塞当前线程直至同步线程内的事件(block)执行完，至于是否会发生死锁，就得看同步线程所阻塞的线程是否存在它的线程队列（queue）中。 123current threaddispatch_sync(queue), block) 第一个例子中，current thread 为主线程，queue 主线程队列，主线程属于主线程队列，所以造成死锁。 第二个例子中，current thread 为我们所开启的异步线程 dispatch_async，并且放在我们自己所创建的 dispatch_queue_t queue = dispatch_queue_create(&quot;com.queue.concurrent&quot;, DISPATCH_QUEUE_CONCURRENT); 异步线程队列中，queue 为主线程队列，异步线程 dispatch_async 并不属于主线程队列中，所以并没有造成死锁。 异步串行队列和同步串行队列首先我们做一个比较，在串行队列中开启一个异步线程，然后再异步线程的事件中再开启一个同步线程。（默认下面例子都是在主线程中运行） 123456789101112dispatch_queue_t queue = dispatch_queue_create("com.queue.CONCURRENT", DISPATCH_QUEUE_CONCURRENT);NSLog(@"1");dispatch_async(queue, ^() &#123; NSLog(@"2"); dispatch_sync(queue, ^()&#123; NSLog(@"3"); &#125;); NSLog(@"4");&#125;);NSLog(@"5"); 输出：1，5，2，3，4 然后将 queue 换成一个串行队列，看看效果如何 123456789101112dispatch_queue_t queue2 = dispatch_queue_create("com.queue.SERIAL", DISPATCH_QUEUE_SERIAL);NSLog(@"1");dispatch_async(queue2, ^() &#123; NSLog(@"2"); dispatch_sync(queue2, ^()&#123; NSLog(@"3"); &#125;); NSLog(@"4");&#125;);NSLog(@"5"); 输出：1，5，2 第一个例子使用 DISPATCH_QUEUE_CONCURRENT 并发队列，输出正常，而第二个例子中使用了 DISPATCH_QUEUE_SERIAL 串行队列，发生了死锁，后面的事件 (@”3”) 和事件 (@”4”)便无法执行。 我们首先分析一下第一个例子，为什么并没有发生死锁，首先我们往并发队列 queue 中添加了dispatch_async 异步线程 ，主线程并不等待异步线程的执行，所以事件 (@”1”) 后便马上执行事件 (@”5”)，当内核线程空闲，加载并发队列 queue 中的 dispatch_async 异步线程 并执行线程中的事件(block) 的，事件 (@”2”) 马上就会被执行。当遇到了 dispatch_sync 同步线程的时候，当前线程，也就是 dispatch_async 这个异步线程会进入阻塞，等待 dispatch_sync 同步线程内的事件(block) 执行完，才可以往下执行事件(@”4”)，我们并将dispatch_sync 同步线程放进了 queue 并发队列当中去，并发队列的特点就是逻辑上是一起执行的，所以 dispatch_sync 同步线程加入 queue 后就马上被执行了，当事件(@”3”)执行完后并且返回，阻塞放开，事件(@”4”)并马上被执行。全过程并没有发生死锁。 我们再来看看第二个例子，首先我们往串行队列 queue 中添加了dispatch_async 异步线程 ，其后过程跟第一个例子一样，直到遇到了 dispatch_sync(queue2, block) ，dispatch_sync` 同步线程 阻塞了 dispatch_async 异步线程，并将同步线程放进了 queue2 串行队列中，串行队列的特别是遵循 FIFO 特点，要必先执行完 dispatch_async 异步线程的事件(block)，才能执行同步线程 dispatch_sync 的事件 (block)，所以造成了死锁。 AFNetWorking 怎么使用同步线程12345678910111213141516171819202122self.synchronizationQueue = dispatch_queue_create([name cStringUsingEncoding:NSASCIIStringEncoding], DISPATCH_QUEUE_SERIAL);- (nullable AFImageDownloadReceipt *)downloadImageForURLRequest:(NSURLRequest *)request withReceiptID:(nonnull NSUUID *)receiptID success:(nullable void (^)(NSURLRequest *request, NSHTTPURLResponse * _Nullable response, UIImage *responseObject))success failure:(nullable void (^)(NSURLRequest *request, NSHTTPURLResponse * _Nullable response, NSError *error))failure &#123; dispatch_sync(self.synchronizationQueue, ^&#123; NSString *URLIdentifier = request.URL.absoluteString; if (URLIdentifier == nil) &#123; if (failure) &#123; NSError *error; dispatch_async(dispatch_get_main_queue(), ^&#123; failure(request, nil, error); &#125;); &#125; return; &#125; ... &#125;);&#125; 上面一段代码才子 AFNetWorking 中的 AFImageDownloader.m 文件当中，作者创建了 synchronizationQueue 串行队列专门用作阻塞当前线程，限制性同步队列中的事件，判断 url 是否为空，但是为什么要这样做呢？ 原因1：因为对象方法 downloadImageForURLRequest:withReceiptID:success:failure 是同一个对象在多个异步线程的并发队列当中执行的，因为并发在逻辑上会同时触发异步线程，那么传进来的参数（request，receiptID，success，failure）会由于资源竞争(condition race) 的情况下会被覆盖，所以我们需要进行阻塞这个线程，先执行完一个请求后再执行另外一个请求。 但是会有人问：为什么么不用 @synchronized (&lt;#lock#&gt;) {} ?因为我们首先不确定调用对象方法downloadImageForURLRequest:withReceiptID:success:failure是否必定在异步线程中被调用，莫名的加锁会消耗资源，当我们使用了dispatch_sync(self.synchronizationQueue,block)后，如果主线程当中被调用，也只会忽视这个方法，直接调用 block，因为阻塞主线程，往并不是主线程队列的线程队列中添加事件，是没有意义的。 使用 dispatch_sync(self.synchronizationQueue,block) 需要注意什么问题？其实上面这么写，是有问题的，当方法 downloadImageForURLRequest:withReceiptID:success:failure 的调用上层，也是dispatch_sync(self.synchronizationQueue,block) 的情况下，就会造成死锁，就像下面一样： 1234567dispatch_sync(self.synchronizationQueue, ^()&#123; NSLog(@"2"); dispatch_sync(self.synchronizationQueue, ^()&#123; NSLog(@"3"); &#125;); NSLog(@"4");&#125;); 或1234567dispatch_async(self.synchronizationQueue, ^()&#123; NSLog(@"2"); dispatch_sync(self.synchronizationQueue, ^()&#123; NSLog(@"3"); &#125;); NSLog(@"4");&#125;); 至于怎么分析，为什么会发生死锁，各位看官，这就留给你们的作业，看了这么多，相信大家也会明白，特别是第二个例子，我们刚讲过，希望大家能在这篇博客中学到东西。 线程与队列的区分说了这么多，大家都对队列和线程有了比较深刻的理解，这个时候有同学就会问，我们该怎么区分我们的block是在主线程中调用还是在子线程调用呢？这是什么意思？我们来看看代码：1234dispatch_sync(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^&#123; NSThread* thread = [NSThread currentThread]; NSLog(@"%@", thread);&#125;); 想象一下，thread是主线程还是子线程？答案当然是主线程了，为什么？因为block执行那个线程上，跟是在串行队列还是并行队列是没有关系的，线程队列的概念只是负责把block事件放在自己的缓冲区中排好队，然后判断是串行队列还是并行队列来把缓冲区的队列进行顺序执行还是一起执行。而代码中开启了一个同步线程，阻塞了主线程，所以block必须在主线程中执行，而且与此同时，全局并发队列中的所有事件也会一起执行(看上去是这样的，实际上还是有一定的顺序，只是通过时间片不断切换，看上去好像是并发). 再看看另一个例子：12345dispatch_queue_t queue = dispatch_queue_create("com.ser.yy", DISPATCH_QUEUE_SERIAL);dispatch_async(queue, ^&#123; NSThread* thread = [NSThread currentThread]; NSLog(@"%@", thread);&#125;); 这里创建了一个异步线程，但却把block事件放在在串行队列中。所以block会放在一条子线程上面，并等待串行队列queue前面的事件执行完了，才会在子线程中执行。 再看以下例子：1234567dispatch_queue_t queue = dispatch_queue_create("com.ser.yy", DISPATCH_QUEUE_SERIAL);dispatch_async(queue, ^&#123; dispatch_sync(dispatch_get_main_queue(), ^&#123; NSThread* thread = [NSThread currentThread]; NSLog(@"%@", thread); &#125;);&#125;); 例子中，把异步线程事件block1放在串行队列中，然后在事件block1中开启了一个同步线程事件block2放在主线程当中来执行.很显然，thread就是子线程。 其实大家很快就发现一个规律，同步线程dispatch_sync的事件block，它的执行线程便是被阻塞的线程！而异步线程dispatch_async的事件block,除了放在主队列dispatch_get_main_queue中，其他都会在子线程中执行！ 为什么异步线程dispatch_async的事件block,除了放在主队列dispatch_get_main_queue中，其他都会在子线程中执行呢？1234dispatch_async(dispatch_get_main_queue(), ^&#123; NSThread* thread = [NSThread currentThread]; NSLog(@"%@", thread);&#125;); 因为主队列dispatch_get_main_queue是一个串行队列，更重要的是它会将所有事件block都会放在主线程这一条线程中执行！ 写在最后： 为什么要写这篇文章呢？主要今天在某公司面试的时候，被问到了关于 GCD 的线程问题，在我说出来答案后，面试官依然坚持已见，认为我是错的，写这篇博客的目的在于，不管这个面试官是否会游览博客，也让更多的面试官可以好好更新自己的知识储备库，不要做井底之蛙。其实在我看来，面试是一个双向交流的过程，我并不在意是否能你们公司工作，毕竟我也不想同事是一群无法交流的人，一个开心愉快并且能够助我成长的工作环境才是我真正需要的。]]></content>
      <tags>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机程序编译过程]]></title>
    <url>%2F2018%2F04%2F02%2Fprogram-compile-introduction%2F</url>
    <content type="text"><![CDATA[现在这个社会充斥着太多的水货程序员了，他们不懂任何计算机原理，但是他们依旧做着公司的业务，很好的完成老板交代的任务，但是这些东西永远对他们来说都说一个黑盒子，他们不会知道为什么会产生段错误，为什么会有悬挂指针，不知道为什么会产生链接错误，什么是缺失符号，更不知道为什么函数 return 一个局部变量就会段错误，返回一个字面量常量就不会，当发生这些问题来只能谷歌，stackoverflow，甚至只能是百度。所以，这里一步一步给大家科普，不断普及一些“常识”让大家更好的理解我们编写的软件程序。 计算机程序编译过程分为4个步骤： 预处理 编译 汇编 链接 预处理1$gcc -E hello.c -o hello.i 或1$cpp hello.c &gt; hello.i 预编译过程主要： 处理预编译指令，例如 #define，#if，#ifdefine 等。 将 #include 包含文件插入到该预编译指令的位置 删除所有的注析 // 、/**/ 编译1$gcc –S hello.i –o hello.s 或1$gcc –S hello.c –o hello.s 编译代表了一整个过程： 词法分析 语法分析 语义分析 源代码优化 代码生成 目标代码优化 词法分析扫描字节序并产生记号。词法分析产生的记号一般可以分为如下几类：关键字、标识符、字面量（包含数字、字符串等）和特殊符号（如加号、等号）。 语法分析语法分析器（Grammar Parser）将对由扫描器产生的记号进行语法分析，从而产生语法树（Syntax Tree）。由语法分析器生成的语法树就是以表达式（Expression）为节点的树。 语义分析语法分析仅仅是完成了对表达式的语法层面的分析，但是它并不了解这个语句是否真正有意义。编译器所能分析的语义是静态语义（Static Semantic），所谓静态语义是指在编译期可以确定的语义，与之对应的动态语义（Dynamic Semantic）就是只有在运行期才能确定的语义。静态语义通常包括声明和类型的匹配，类型的转换。 动态语义和静态语义? 比如将一个浮点型赋值给一个指针的时候，语义分析程序会发现这个类型不匹配，编译器将会报错。动态语义一般指在运行期出现的语义相关的问题，比如将0作为除数是一个运行期语义错误。 中间语言生成中间代码使得编译器可以被分为前端和后端。编译器前端负责产生机器无关的中间代码，编译器后端将中间代码转换成目标机器代码。这样对于一些可以跨平台的编译器而言，它们可以针对不同的平台使用同一个前端和针对不同机器平台的数个后端。 目标代码生成与优化 代码级优化器产生中间代码标志着下面的过程都属于编译器后端。编译器后端主要包括代码生成器（Code Generator）和目标代码优化器（Target Code Optimizer）。 代码生成器将中间代码转换成目标机器代码，这个过程十分依赖于目标机器。 对于上面例子中的中间代码，代码生成器可能会生成下面的代码序列12345movl index, %ecx ; value of index to ecxaddl $4, %ecx ; ecx = ecx + 4mull $8, %ecx ; ecx = ecx * 8movl index, %eax ; value of index to eaxmovl %ecx, array(,eax,4) ; array[index] = ecx 汇编1$as hello.s –o hello.o 或1$gcc –c hello.c –o hello.o 汇编器(as)将汇编代码翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序(relocatable)的格式，并将结果保持在目标文件 hello.o 中。hello.o 是一个二进制文件。 链接1$ld -static /usr/lib/crt1.o /usr/lib/crti.o /usr/lib/gcc/i486-linux-gnu/4.1.3/crtbeginT.o -L/usr/lib/gcc/i486-linux-gnu/4.1.3 -L/usr/lib -L/lib hello.o --start-group -lgcc -lgcc_eh -lc --end-group /usr/lib/gcc/i486-linux-gnu/4.1.3/crtend.o /usr/lib/crtn.o 链接阶段最重要的工作就是重定位，将所有的目标文件都链接起来，在 #include 文件中的函数声明原本只会生成一个没有跳转地址的指令，重定位的工作在其他目标文件中找到这些目标地址，并把地址填补进去。 链接分为静态链接和动态链接，也就是我们通常说的私有对象和共享对象。这里得展开另外一篇来讲了，内容太多。 链接就像将所有的组件合成一起，组成一个整体。]]></content>
      <tags>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++项目中遇到的一些方法归纳(持续更新)]]></title>
    <url>%2F2018%2F04%2F02%2Fcpp-project-new-learning%2F</url>
    <content type="text"><![CDATA[浏览 C++ 项目中收集到的代码学习片段 将 string 类型，转换为模板类型123456template &lt;typename P0&gt; bool FromString(const std::string&amp; s, P0* p) &#123; std::istringstream iss(s); iss &gt;&gt; std::boolalpha &gt;&gt; *p; return !iss.fail(); &#125; 将模板类型 ，转换为string 类型12345678template &lt;class T&gt;static bool ToString(const T &amp;t, std::string* s) &#123; RTC_DCHECK(s); std::ostringstream oss; oss &lt;&lt; std::boolalpha &lt;&lt; t; *s = oss.str(); return !oss.fail();&#125; Mach内核获得Cpu使用率百分比1234567891011121314151617181920212223242526272829NSInteger ARDGetCpuUsagePercentage() &#123; // Create an array of thread ports for the current task. const task_t task = mach_task_self(); thread_act_array_t thread_array; mach_msg_type_number_t thread_count; if (task_threads(task, &amp;thread_array, &amp;thread_count) != KERN_SUCCESS) &#123; return -1; &#125; // Sum cpu usage from all threads. float cpu_usage_percentage = 0; thread_basic_info_data_t thread_info_data = &#123;&#125;; mach_msg_type_number_t thread_info_count; for (size_t i = 0; i &lt; thread_count; ++i) &#123; thread_info_count = THREAD_BASIC_INFO_COUNT; kern_return_t ret = thread_info(thread_array[i], THREAD_BASIC_INFO, (thread_info_t)&amp;thread_info_data, &amp;thread_info_count); if (ret == KERN_SUCCESS) &#123; cpu_usage_percentage += 100.f * (float)thread_info_data.cpu_usage / TH_USAGE_SCALE; &#125; &#125; // Dealloc the created array. vm_deallocate(task, (vm_address_t)thread_array, sizeof(thread_act_t) * thread_count); return lroundf(cpu_usage_percentage); 字节对齐8个字节对齐1234567# define WORD_MASK 7ULstatic inline uint32_t word_align(uint32_t x) &#123; return static_cast&lt;uint32_t&gt;((x + WORD_MASK) &amp; ~WORD_MASK);&#125;static inline size_t word_align(size_t x) &#123; return (x + WORD_MASK) &amp; ~WORD_MASK;&#125;]]></content>
      <tags>
        <tag>C++, 代码片段</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异步iO的演变历程]]></title>
    <url>%2F2018%2F04%2F02%2Fasynchronous-io-introduction%2F</url>
    <content type="text"><![CDATA[英文原文 大多数编程都是从阻塞IO开始的，一个 IO 的调用是同步的，当你调用它时，他会一直等待到操作完成后才返回，或者等到足够时间的时候后你的网络堆栈主动放弃。当你在 TCP 连接上调用 “connect()” ，例如你操作系统发送 SYN 数据包到 TCP 连接的另一端主机的时。它不会立即将控制权返回给你的应用程序，而直到它收到来自对方主机的SYN ACK数据包，或者直到超时后主动放弃的时候，才会将控制权返回。 这是一个客户端非常简单的使用阻塞网络函数的的例子。例子中打开与www.google.com的连接，向www.google.com 发送一个简单的HTTP请求，并将响应打印到stdout Example: A simple blocking HTTP client 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* For sockaddr_in */#include &lt;netinet/in.h&gt;/* For socket functions */#include &lt;sys/socket.h&gt;/* For gethostbyname */#include &lt;netdb.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;int main(int c, char **v)&#123; const char query[] = "GET / HTTP/1.0\r\n" "Host: www.google.com\r\n" "\r\n"; const char hostname[] = "www.google.com"; struct sockaddr_in sin; struct hostent *h; const char *cp; int fd; ssize_t n_written, remaining; char buf[1024]; /* Look up the IP address for the hostname. Watch out; this isn't threadsafe on most platforms. */ h = gethostbyname(hostname); if (!h) &#123; fprintf(stderr, "Couldn't lookup %s: %s", hostname, hstrerror(h_errno)); return 1; &#125; if (h-&gt;h_addrtype != AF_INET) &#123; fprintf(stderr, "No ipv6 support, sorry."); return 1; &#125; /* Allocate a new socket */ fd = socket(AF_INET, SOCK_STREAM, 0); if (fd &lt; 0) &#123; perror("socket"); return 1; &#125; /* Connect to the remote host. */ sin.sin_family = AF_INET; sin.sin_port = htons(80); sin.sin_addr = *(struct in_addr*)h-&gt;h_addr; if (connect(fd, (struct sockaddr*) &amp;sin, sizeof(sin))) &#123; perror("connect"); close(fd); return 1; &#125; /* Write the query. */ /* XXX Can send succeed partially? */ cp = query; remaining = strlen(query); while (remaining) &#123; n_written = send(fd, cp, remaining, 0); if (n_written &lt;= 0) &#123; perror("send"); return 1; &#125; remaining -= n_written; cp += n_written; &#125; /* Get an answer back. */ while (1) &#123; ssize_t result = recv(fd, buf, sizeof(buf), 0); if (result == 0) &#123; break; &#125; else if (result &lt; 0) &#123; perror("recv"); close(fd); return 1; &#125; fwrite(buf, 1, result, stdout); &#125; close(fd); return 0;&#125; 在上面代码中所有的网络函数都是阻塞的：在解析 www.google.com 成功或失败之前，gethostbyname 函数不会返回。connect 函数直到它已经连接才会返回。recv 函数在收到数据或 close 之前不会返回;并且send 函数不会返回，直到它至少将其输出刷新到内核的写缓冲区。 其实阻塞 IO 不一定是一件坏事。如果你不希望同时处理某些事情的时候，那么阻塞 IO 是非常合适的。但是，假设你需要编写一个程序来同时处理多个连接，这个时候阻塞 IO 就非常不适合我们了。为了使我们的例子具体化：假设你想要从两个连接读取输入，并且你不知道哪个连接首先得到输入。 You can’t say Bad Example 1234567891011121314/* This won't work. */char buf[1024];int i, n;while (i_still_want_to_read()) &#123; for (i=0; i&lt;n_sockets; ++i) &#123; n = recv(fd[i], buf, sizeof(buf), 0); if (n==0) handle_close(fd[i]); else if (n&lt;0) handle_error(fd[i], errno); else handle_input(fd[i], buf, n); &#125;&#125; 因为如果数据首先到达fd [2],直到 fd [0]和fd [1]的读取已经获得一些数据并结束为止，程序甚至不会尝试读取fd [2]。 有时人们通过多线程或者多进程的方式去解决这个问题。一个最简单使用多线程的方式是通过分离进程(或者线程)去处理每个连接。由于每个连接都有自己的进程，等待一个连接的阻塞IO调用将不会使任何其他连接的进程阻塞。 这里有另外一个示例程序。这是一个微不足道的服务器，它监听者端口40713上的TCP连接，一次从它的输入中读取一行数据，并在每一行到达时写出ROT13混淆，它使用 Unix fork() 函数为每个传入的连接创建一个新的进程 Example: Forking ROT13 server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* For sockaddr_in */#include &lt;netinet/in.h&gt;/* For socket functions */#include &lt;sys/socket.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define MAX_LINE 16384charrot13_char(char c)&#123; /* We don't want to use isalpha here; setting the locale would change * which characters are considered alphabetical. */ if ((c &gt;= 'a' &amp;&amp; c &lt;= 'm') || (c &gt;= 'A' &amp;&amp; c &lt;= 'M')) return c + 13; else if ((c &gt;= 'n' &amp;&amp; c &lt;= 'z') || (c &gt;= 'N' &amp;&amp; c &lt;= 'Z')) return c - 13; else return c;&#125;voidchild(int fd)&#123; char outbuf[MAX_LINE+1]; size_t outbuf_used = 0; ssize_t result; while (1) &#123; char ch; result = recv(fd, &amp;ch, 1, 0); if (result == 0) &#123; break; &#125; else if (result == -1) &#123; perror("read"); break; &#125; /* We do this test to keep the user from overflowing the buffer. */ if (outbuf_used &lt; sizeof(outbuf)) &#123; outbuf[outbuf_used++] = rot13_char(ch); &#125; if (ch == '\n') &#123; send(fd, outbuf, outbuf_used, 0); outbuf_used = 0; continue; &#125; &#125;&#125;voidrun(void)&#123; int listener; struct sockaddr_in sin; sin.sin_family = AF_INET; sin.sin_addr.s_addr = 0; sin.sin_port = htons(40713); listener = socket(AF_INET, SOCK_STREAM, 0);#ifndef WIN32 &#123; int one = 1; setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, &amp;one, sizeof(one)); &#125;#endif if (bind(listener, (struct sockaddr*)&amp;sin, sizeof(sin)) &lt; 0) &#123; perror("bind"); return; &#125; if (listen(listener, 16)&lt;0) &#123; perror("listen"); return; &#125; while (1) &#123; struct sockaddr_storage ss; socklen_t slen = sizeof(ss); int fd = accept(listener, (struct sockaddr*)&amp;ss, &amp;slen); if (fd &lt; 0) &#123; perror("accept"); &#125; else &#123; if (fork() == 0) &#123; child(fd); exit(0); &#125; &#125; &#125;&#125;intmain(int c, char **v)&#123; run(); return 0;&#125; 所以，我们拥有同时处理多个连接的完美解决方案了吗？我可以停止写这篇文章了吗？还不行。首先，进程的创建（还有事件线程的创建）在一些平台上可能是非常昂贵的。在现实场景当中，你更希望使用线程池而不是创建一个新的进程对象。但其实，线程的消耗并不是像你想的那么小。如果你的程序需要一次性的操作成千上万的连接，数以万计的线程将会使你的的 CPU 并不会像对待只有几个线程那样高效了。 但是如果线程不是处理多连接的完美解决方案，哪最终方案到底在哪里？在Unix范例中，你可以使你的 sockets 不受阻塞。Unix函数如下： fcntl(fd, F_SETFL, O_NONBLOCK);fd 是 socket 的文件描述符[一个文件描述符是打开它时内核分配给 socket 的编号。你可以使用该编号让Unix 函数可以引用到该 socket]一旦你使得fd( socket 套接字)不阻塞，那么无论何时你对fd进行网络函数调用（因为网络函数都是阻塞）的，它都会马上完成操作或者返回一个特别的错误代码:” couldn’t make any progress now, try again.”。所以我们的双套接字示例程序被天真的写成如下： Bad Example: busy-polling all sockets123456789101112131415161718192021/* This will work, but the performance will be unforgivably bad. */int i, n;char buf[1024];for (i=0; i &lt; n_sockets; ++i) fcntl(fd[i], F_SETFL, O_NONBLOCK);while (i_still_want_to_read()) &#123; for (i=0; i &lt; n_sockets; ++i) &#123; n = recv(fd[i], buf, sizeof(buf), 0); if (n == 0) &#123; handle_close(fd[i]); &#125; else if (n &lt; 0) &#123; if (errno == EAGAIN) ; /* The kernel didn't have any data for us to read. */ else handle_error(fd[i], errno); &#125; else &#123; handle_input(fd[i], buf, n); &#125; &#125;&#125; 我们现在使用了非阻塞的 sockets，上述代码是可以运行，但仅此而已。它的性能将会非常差，有两个原因：第一，当所有的连接都没有数据读取的时候，while 和 for 操作将无限循环，耗尽了你的 CPU 周期。第二，如果你尝试用这种方法处理多于一个或两个连接，不管你是否有数据需要处理，都将为每个连接执行一次内核调用。所以，我们所需的方式是告诉内核”等待到其中一个 socket 准备好传递数据给我们的时候，才告诉我们那个socket 已经准备就绪。” The oldest solution that people still use for this problem is select(). The select() call takes three sets of fds (implemented as bit arrays): one for reading, one for writing, and one for “exceptions”. It waits until a socket from one of the sets is ready and alters the sets to contain only the sockets ready for use. 人们解决这个问题最常用的方法就是使用 select() 函数。使用 select() 函数解决这个问题的时候需要使用三个 fds(位数组的实现) 集合：分别处理 读、写 和 “异常” 操作。select()函数会一直等待，直到来自数组中的某一个 socket 准备就绪时，修改参数的集合并将准备就绪的 socket 放入作为该集合当中。以下使用 select 函数重新实现我们的示例: Example: Using select1234567891011121314151617181920212223242526272829303132333435/* If you only have a couple dozen fds, this version won't be awful */fd_set readset;int i, n;char buf[1024];while (i_still_want_to_read()) &#123; int maxfd = -1; FD_ZERO(&amp;readset); /* Add all of the interesting fds to readset */ for (i=0; i &lt; n_sockets; ++i) &#123; if (fd[i]&gt;maxfd) maxfd = fd[i]; FD_SET(fd[i], &amp;readset); &#125; /* Wait until one or more fds are ready to read */ select(maxfd+1, &amp;readset, NULL, NULL, NULL); /* Process all of the fds that are still set in readset */ for (i=0; i &lt; n_sockets; ++i) &#123; if (FD_ISSET(fd[i], &amp;readset)) &#123; n = recv(fd[i], buf, sizeof(buf), 0); if (n == 0) &#123; handle_close(fd[i]); &#125; else if (n &lt; 0) &#123; if (errno == EAGAIN) ; /* The kernel didn't have any data for us to read. */ else handle_error(fd[i], errno); &#125; else &#123; handle_input(fd[i], buf, n); &#125; &#125; &#125;&#125; 这次使用了 select() 函数重新实现了我们的 ROT13 服务器。 Example: select()-based ROT13 server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228/* For sockaddr_in */#include &lt;netinet/in.h&gt;/* For socket functions */#include &lt;sys/socket.h&gt;/* For fcntl */#include &lt;fcntl.h&gt;/* for select */#include &lt;sys/select.h&gt;#include &lt;assert.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#define MAX_LINE 16384charrot13_char(char c)&#123; /* We don't want to use isalpha here; setting the locale would change * which characters are considered alphabetical. */ if ((c &gt;= 'a' &amp;&amp; c &lt;= 'm') || (c &gt;= 'A' &amp;&amp; c &lt;= 'M')) return c + 13; else if ((c &gt;= 'n' &amp;&amp; c &lt;= 'z') || (c &gt;= 'N' &amp;&amp; c &lt;= 'Z')) return c - 13; else return c;&#125;struct fd_state &#123; char buffer[MAX_LINE]; size_t buffer_used; int writing; size_t n_written; size_t write_upto;&#125;;struct fd_state *alloc_fd_state(void)&#123; struct fd_state *state = malloc(sizeof(struct fd_state)); if (!state) return NULL; state-&gt;buffer_used = state-&gt;n_written = state-&gt;writing = state-&gt;write_upto = 0; return state;&#125;voidfree_fd_state(struct fd_state *state)&#123; free(state);&#125;voidmake_nonblocking(int fd)&#123; fcntl(fd, F_SETFL, O_NONBLOCK);&#125;intdo_read(int fd, struct fd_state *state)&#123; char buf[1024]; int i; ssize_t result; while (1) &#123; result = recv(fd, buf, sizeof(buf), 0); if (result &lt;= 0) break; for (i=0; i &lt; result; ++i) &#123; if (state-&gt;buffer_used &lt; sizeof(state-&gt;buffer)) state-&gt;buffer[state-&gt;buffer_used++] = rot13_char(buf[i]); if (buf[i] == '\n') &#123; state-&gt;writing = 1; state-&gt;write_upto = state-&gt;buffer_used; &#125; &#125; &#125; if (result == 0) &#123; return 1; &#125; else if (result &lt; 0) &#123; if (errno == EAGAIN) return 0; return -1; &#125; return 0;&#125;intdo_write(int fd, struct fd_state *state)&#123; while (state-&gt;n_written &lt; state-&gt;write_upto) &#123; ssize_t result = send(fd, state-&gt;buffer + state-&gt;n_written, state-&gt;write_upto - state-&gt;n_written, 0); if (result &lt; 0) &#123; if (errno == EAGAIN) return 0; return -1; &#125; assert(result != 0); state-&gt;n_written += result; &#125; if (state-&gt;n_written == state-&gt;buffer_used) state-&gt;n_written = state-&gt;write_upto = state-&gt;buffer_used = 0; state-&gt;writing = 0; return 0;&#125;voidrun(void)&#123; int listener; struct fd_state *state[FD_SETSIZE]; struct sockaddr_in sin; int i, maxfd; fd_set readset, writeset, exset; // 三组操作，读、写和异常 sin.sin_family = AF_INET; sin.sin_addr.s_addr = 0; sin.sin_port = htons(40713); for (i = 0; i &lt; FD_SETSIZE; ++i) state[i] = NULL; listener = socket(AF_INET, SOCK_STREAM, 0); make_nonblocking(listener);#ifndef WIN32 &#123; int one = 1; setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, &amp;one, sizeof(one)); &#125;#endif if (bind(listener, (struct sockaddr*)&amp;sin, sizeof(sin)) &lt; 0) &#123; perror("bind"); return; &#125; if (listen(listener, 16)&lt;0) &#123; perror("listen"); return; &#125; FD_ZERO(&amp;readset); FD_ZERO(&amp;writeset); FD_ZERO(&amp;exset); while (1) &#123; maxfd = listener; FD_ZERO(&amp;readset); FD_ZERO(&amp;writeset); FD_ZERO(&amp;exset); FD_SET(listener, &amp;readset); for (i=0; i &lt; FD_SETSIZE; ++i) &#123; if (state[i]) &#123; if (i &gt; maxfd) maxfd = i; FD_SET(i, &amp;readset); if (state[i]-&gt;writing) &#123; FD_SET(i, &amp;writeset); &#125; &#125; &#125; if (select(maxfd+1, &amp;readset, &amp;writeset, &amp;exset, NULL) &lt; 0) &#123; perror("select"); return; &#125; if (FD_ISSET(listener, &amp;readset)) &#123; struct sockaddr_storage ss; socklen_t slen = sizeof(ss); int fd = accept(listener, (struct sockaddr*)&amp;ss, &amp;slen); if (fd &lt; 0) &#123; perror("accept"); &#125; else if (fd &gt; FD_SETSIZE) &#123; close(fd); &#125; else &#123; make_nonblocking(fd); state[fd] = alloc_fd_state(); assert(state[fd]);/*XXX*/ &#125; &#125; for (i=0; i &lt; maxfd+1; ++i) &#123; int r = 0; if (i == listener) continue; if (FD_ISSET(i, &amp;readset)) &#123; r = do_read(i, state[i]); &#125; if (r == 0 &amp;&amp; FD_ISSET(i, &amp;writeset)) &#123; // 如果没有读操作的时候才查看是否有写操作 r = do_write(i, state[i]); &#125; if (r) &#123; free_fd_state(state[i]); state[i] = NULL; close(i); &#125; &#125; &#125;&#125;intmain(int c, char **v)&#123; setvbuf(stdout, NULL, _IONBF, 0); run(); return 0;&#125; 但是我们依然还是没有完成。因为生成和读取 select() 的位数组的时间与你为select() 提供的最大 fd 成正比，当 sockets 数量非常多的时候，select() 函数调用的规模也就变得非常大。(因为 select() 函数就是一个轮询操作)对用户空间而言，生成和读取位数组的时间与你为 select() 供的fds数量成正比。但对内核空间而言，读取位数组所花费的时间与位数组中最大的 fd 成正比。无论在select() 将多少个 fds 添加到集合中，这往往是整个程序中使用的 fds 总数的一半。 不用的操作系统会提供取代 select 的其他函数。其中包括 poll(), epoll(), kqueue(), evports, and /dev/poll。这里所有的函数表现出来的性能都比 select() 要好，而且除了 poll() 之外，其他所有函数用于添加 socket，删除 socket 以及通知(socket 已准备好用于IO)操作都可以提供 O(1) 的性能。 不幸的是，这些高效的接口并没有普及成标准。Linux 用的是 epoll(), 在 BSD(包括 Darwin)用的是 kqueue()，Solaris 用的是 evports 和 /dev/poll… 这些操作系统各自为政。所以，如果你想写出一个轻量且搞性能的异步应用的话，你需要抽象的封装着所有接口，并且为接口使用者选择最有效的一个。 这就是Libevent API的底层所做的事情，它对不同种类的 select() 替代函数提供了一致的接口，在计算机运行当中使用了最高效可用的版本。 这是我们的异步ROT13服务器的另一个版本。这次，它使用Libevent 2而不是select()，注意，现在fd_sets已经消失：相反，我们可以将事件与结构event_base关联和解除关联, 这是用select(), poll(), epoll(), kqueue() 等方式实现的。 Example: A low-level ROT13 server with Libevent123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210/* For sockaddr_in */#include &lt;netinet/in.h&gt;/* For socket functions */#include &lt;sys/socket.h&gt;/* For fcntl */#include &lt;fcntl.h&gt;#include &lt;event2/event.h&gt;#include &lt;assert.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#define MAX_LINE 16384void do_read(evutil_socket_t fd, short events, void *arg);void do_write(evutil_socket_t fd, short events, void *arg);charrot13_char(char c)&#123; /* We don't want to use isalpha here; setting the locale would change * which characters are considered alphabetical. */ if ((c &gt;= 'a' &amp;&amp; c &lt;= 'm') || (c &gt;= 'A' &amp;&amp; c &lt;= 'M')) return c + 13; else if ((c &gt;= 'n' &amp;&amp; c &lt;= 'z') || (c &gt;= 'N' &amp;&amp; c &lt;= 'Z')) return c - 13; else return c;&#125;struct fd_state &#123; char buffer[MAX_LINE]; size_t buffer_used; size_t n_written; size_t write_upto; struct event *read_event; struct event *write_event;&#125;;struct fd_state *alloc_fd_state(struct event_base *base, evutil_socket_t fd)&#123; struct fd_state *state = malloc(sizeof(struct fd_state)); if (!state) return NULL; state-&gt;read_event = event_new(base, fd, EV_READ|EV_PERSIST, do_read, state); if (!state-&gt;read_event) &#123; free(state); return NULL; &#125; state-&gt;write_event = event_new(base, fd, EV_WRITE|EV_PERSIST, do_write, state); if (!state-&gt;write_event) &#123; event_free(state-&gt;read_event); free(state); return NULL; &#125; state-&gt;buffer_used = state-&gt;n_written = state-&gt;write_upto = 0; assert(state-&gt;write_event); return state;&#125;voidfree_fd_state(struct fd_state *state)&#123; event_free(state-&gt;read_event); event_free(state-&gt;write_event); free(state);&#125;voiddo_read(evutil_socket_t fd, short events, void *arg)&#123; struct fd_state *state = arg; char buf[1024]; int i; ssize_t result; while (1) &#123; assert(state-&gt;write_event); result = recv(fd, buf, sizeof(buf), 0); if (result &lt;= 0) break; for (i=0; i &lt; result; ++i) &#123; if (state-&gt;buffer_used &lt; sizeof(state-&gt;buffer)) state-&gt;buffer[state-&gt;buffer_used++] = rot13_char(buf[i]); if (buf[i] == '\n') &#123; assert(state-&gt;write_event); event_add(state-&gt;write_event, NULL); state-&gt;write_upto = state-&gt;buffer_used; &#125; &#125; &#125; if (result == 0) &#123; free_fd_state(state); &#125; else if (result &lt; 0) &#123; if (errno == EAGAIN) // XXXX use evutil macro return; perror("recv"); free_fd_state(state); &#125;&#125;voiddo_write(evutil_socket_t fd, short events, void *arg)&#123; struct fd_state *state = arg; while (state-&gt;n_written &lt; state-&gt;write_upto) &#123; ssize_t result = send(fd, state-&gt;buffer + state-&gt;n_written, state-&gt;write_upto - state-&gt;n_written, 0); if (result &lt; 0) &#123; if (errno == EAGAIN) // XXX use evutil macro return; free_fd_state(state); return; &#125; assert(result != 0); state-&gt;n_written += result; &#125; if (state-&gt;n_written == state-&gt;buffer_used) state-&gt;n_written = state-&gt;write_upto = state-&gt;buffer_used = 1; event_del(state-&gt;write_event);&#125;voiddo_accept(evutil_socket_t listener, short event, void *arg)&#123; struct event_base *base = arg; struct sockaddr_storage ss; socklen_t slen = sizeof(ss); int fd = accept(listener, (struct sockaddr*)&amp;ss, &amp;slen); if (fd &lt; 0) &#123; // XXXX eagain?? perror("accept"); &#125; else if (fd &gt; FD_SETSIZE) &#123; close(fd); // XXX replace all closes with EVUTIL_CLOSESOCKET */ &#125; else &#123; struct fd_state *state; evutil_make_socket_nonblocking(fd); state = alloc_fd_state(base, fd); assert(state); /*XXX err*/ assert(state-&gt;write_event); event_add(state-&gt;read_event, NULL); &#125;&#125;voidrun(void)&#123; evutil_socket_t listener; struct sockaddr_in sin; struct event_base *base; struct event *listener_event; base = event_base_new(); if (!base) return; /*XXXerr*/ sin.sin_family = AF_INET; sin.sin_addr.s_addr = 0; sin.sin_port = htons(40713); listener = socket(AF_INET, SOCK_STREAM, 0); evutil_make_socket_nonblocking(listener);#ifndef WIN32 &#123; int one = 1; setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, &amp;one, sizeof(one)); &#125;#endif if (bind(listener, (struct sockaddr*)&amp;sin, sizeof(sin)) &lt; 0) &#123; perror("bind"); return; &#125; if (listen(listener, 16)&lt;0) &#123; perror("listen"); return; &#125; listener_event = event_new(base, listener, EV_READ|EV_PERSIST, do_accept, (void*)base); /*XXX check it */ event_add(listener_event, NULL); event_base_dispatch(base);&#125;intmain(int c, char **v)&#123; setvbuf(stdout, NULL, _IONBF, 0); run(); return 0;&#125; 代码中值得注意的是：sockets 并不是用 int 代表，而是用 evutil_socket_t 类型。并不是调用 fcntl(O_NONBLOCK) 让 sockets 变成非阻塞，而是调用 evutil_make_socket_nonblocking。这些改变让我们的代码兼容了 Win32 网络 API 的不同部分。 What about convenience? (and what about Windows?)你可能注意到，当我们的代码变得更高效的同时，也变得更加复杂了。回到我们使用 fork 的时候，我们并不需要为每个连接管理一个缓冲区。我们仅仅为每个进程分配了一个单独的栈分配缓冲区。我们不需要明确地追中每个 socket 是读还是写：这在我们的代码中是隐含的。(child 函数每个进程自己管理 socket 读写)。我们不需要一个结构来跟踪每个操作已完成多少：我们只是使用循环和栈变量。 此外，如果你对 Windows 的网络开发有深入了解，你将会意识到用在上面的例子当中 libevent 可能没有表现出最佳性能。在Windows上，快速异步IO的方式不是使用类 select() 接口：而是通过使用IOCP（IO Completion Ports）API。跟其他快速网络 API 不同，当 socket 准备好执行您的程序必须执行的操作时，IOCP不会通知你的程序。相反，程序会通知 Windows 网络栈启动网络操作，IOCP 会在操作完成时告诉程序。 幸运的是，Libevent 2 的 “bufferevents” 接口解决了这两个问题：它使程序编写起来更加简单，并提供了在 Windows 和 Unix 上高效实现的接口。 这是我们 ROT13 服务器最后一次编码了，使用 bufferevents API。 Example: A simpler ROT13 server with Libevent123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156/* For sockaddr_in */#include &lt;netinet/in.h&gt;/* For socket functions */#include &lt;sys/socket.h&gt;/* For fcntl */#include &lt;fcntl.h&gt;#include &lt;event2/event.h&gt;#include &lt;event2/buffer.h&gt;#include &lt;event2/bufferevent.h&gt;#include &lt;assert.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#define MAX_LINE 16384void do_read(evutil_socket_t fd, short events, void *arg);void do_write(evutil_socket_t fd, short events, void *arg);charrot13_char(char c)&#123; /* We don't want to use isalpha here; setting the locale would change * which characters are considered alphabetical. */ if ((c &gt;= 'a' &amp;&amp; c &lt;= 'm') || (c &gt;= 'A' &amp;&amp; c &lt;= 'M')) return c + 13; else if ((c &gt;= 'n' &amp;&amp; c &lt;= 'z') || (c &gt;= 'N' &amp;&amp; c &lt;= 'Z')) return c - 13; else return c;&#125;voidreadcb(struct bufferevent *bev, void *ctx)&#123; struct evbuffer *input, *output; char *line; size_t n; int i; input = bufferevent_get_input(bev); output = bufferevent_get_output(bev); while ((line = evbuffer_readln(input, &amp;n, EVBUFFER_EOL_LF))) &#123; for (i = 0; i &lt; n; ++i) line[i] = rot13_char(line[i]); evbuffer_add(output, line, n); evbuffer_add(output, "\n", 1); free(line); &#125; if (evbuffer_get_length(input) &gt;= MAX_LINE) &#123; /* Too long; just process what there is and go on so that the buffer * doesn't grow infinitely long. */ char buf[1024]; while (evbuffer_get_length(input)) &#123; int n = evbuffer_remove(input, buf, sizeof(buf)); for (i = 0; i &lt; n; ++i) buf[i] = rot13_char(buf[i]); evbuffer_add(output, buf, n); &#125; evbuffer_add(output, "\n", 1); &#125;&#125;voiderrorcb(struct bufferevent *bev, short error, void *ctx)&#123; if (error &amp; BEV_EVENT_EOF) &#123; /* connection has been closed, do any clean up here */ /* ... */ &#125; else if (error &amp; BEV_EVENT_ERROR) &#123; /* check errno to see what error occurred */ /* ... */ &#125; else if (error &amp; BEV_EVENT_TIMEOUT) &#123; /* must be a timeout event handle, handle it */ /* ... */ &#125; bufferevent_free(bev);&#125;voiddo_accept(evutil_socket_t listener, short event, void *arg)&#123; struct event_base *base = arg; struct sockaddr_storage ss; socklen_t slen = sizeof(ss); int fd = accept(listener, (struct sockaddr*)&amp;ss, &amp;slen); if (fd &lt; 0) &#123; perror("accept"); &#125; else if (fd &gt; FD_SETSIZE) &#123; close(fd); &#125; else &#123; struct bufferevent *bev; evutil_make_socket_nonblocking(fd); bev = bufferevent_socket_new(base, fd, BEV_OPT_CLOSE_ON_FREE); bufferevent_setcb(bev, readcb, NULL, errorcb, NULL); bufferevent_setwatermark(bev, EV_READ, 0, MAX_LINE); bufferevent_enable(bev, EV_READ|EV_WRITE); &#125;&#125;voidrun(void)&#123; evutil_socket_t listener; struct sockaddr_in sin; struct event_base *base; struct event *listener_event; base = event_base_new(); if (!base) return; /*XXXerr*/ sin.sin_family = AF_INET; sin.sin_addr.s_addr = 0; sin.sin_port = htons(40713); listener = socket(AF_INET, SOCK_STREAM, 0); evutil_make_socket_nonblocking(listener);#ifndef WIN32 &#123; int one = 1; setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, &amp;one, sizeof(one)); &#125;#endif if (bind(listener, (struct sockaddr*)&amp;sin, sizeof(sin)) &lt; 0) &#123; perror("bind"); return; &#125; if (listen(listener, 16)&lt;0) &#123; perror("listen"); return; &#125; listener_event = event_new(base, listener, EV_READ|EV_PERSIST, do_accept, (void*)base); /*XXX check it */ event_add(listener_event, NULL); event_base_dispatch(base);&#125;intmain(int c, char **v)&#123; setvbuf(stdout, NULL, _IONBF, 0); run(); return 0;&#125;]]></content>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RAC 源码分析(一)]]></title>
    <url>%2F2018%2F04%2F02%2Frac-source-analyze%2F</url>
    <content type="text"><![CDATA[RecativeCoCoa objectivec 版本的分析，第一部分主要阐述 rac_signalForSelector: 该方法的实现，观摩一下 RAC 是如何监听方法回调的. rac_signalForSelector当我们监听某个变量的变化，很自然我们就想到了 KVO 的方式， 但是我们有想过监听方法吗？在 RAC 当中，我们需要监听某个方法的被调用，就使用到了rac_signalForSelector这个函数。先看一下这个函数的实现方法。 1234567// NSobject+RACSelectorSiganl.m- (RACSignal *)rac_signalForSelector:(SEL)selector &#123; NSCParameterAssert(selector != NULL); return NSObjectRACSignalForSelector(self, selector, NULL);&#125; 方法 rac_signalForSelector 直接调用了静态函数 NSObjectRACSignalForSelector! NSObjectRACSignalForSelector1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// NSobject+RACSelectorSiganl.mstatic RACSignal *NSObjectRACSignalForSelector(NSObject *self, SEL selector, Protocol *protocol) &#123; /** 1.*/ SEL aliasSelector = RACAliasForSelector(selector); @synchronized (self) &#123; /** 2.*/ RACSubject *subject = objc_getAssociatedObject(self, aliasSelector); if (subject != nil) return subject; /** 3.*/ Class class = RACSwizzleClass(self); NSCAssert(class != nil, @"Could not swizzle class of %@", self); /** 4.*/ subject = [[RACSubject subject] setNameWithFormat:@"%@ -rac_signalForSelector: %s", self.rac_description, sel_getName(selector)]; objc_setAssociatedObject(self, aliasSelector, subject, OBJC_ASSOCIATION_RETAIN); [self.rac_deallocDisposable addDisposable:[RACDisposable disposableWithBlock:^&#123; [subject sendCompleted]; &#125;]]; /** 5.*/ Method targetMethod = class_getInstanceMethod(class, selector); if (targetMethod == NULL) &#123; const char *typeEncoding; if (protocol == NULL) &#123; typeEncoding = RACSignatureForUndefinedSelector(selector); &#125; else &#123; // Look for the selector as an optional instance method. struct objc_method_description methodDescription = protocol_getMethodDescription(protocol, selector, NO, YES); if (methodDescription.name == NULL) &#123; methodDescription = protocol_getMethodDescription(protocol, selector, YES, YES); NSCAssert(methodDescription.name != NULL, @"Selector %@ does not exist in &lt;%s&gt;", NSStringFromSelector(selector), protocol_getName(protocol)); &#125; typeEncoding = methodDescription.types; &#125; RACCheckTypeEncoding(typeEncoding); /** 6.*/ if (!class_addMethod(class, selector, _objc_msgForward, typeEncoding)) &#123; NSDictionary *userInfo = @&#123; NSLocalizedDescriptionKey: [NSString stringWithFormat:NSLocalizedString(@"A race condition occurred implementing %@ on class %@", nil), NSStringFromSelector(selector), class], NSLocalizedRecoverySuggestionErrorKey: NSLocalizedString(@"Invoke -rac_signalForSelector: again to override the implementation.", nil) &#125;; return [RACSignal error:[NSError errorWithDomain:RACSelectorSignalErrorDomain code:RACSelectorSignalErrorMethodSwizzlingRace userInfo:userInfo]]; &#125; &#125; else if (method_getImplementation(targetMethod) != _objc_msgForward) &#123; // Make a method alias for the existing method implementation. const char *typeEncoding = method_getTypeEncoding(targetMethod); RACCheckTypeEncoding(typeEncoding); /** 6.*/ BOOL addedAlias __attribute__((unused)) = class_addMethod(class, aliasSelector, method_getImplementation(targetMethod), typeEncoding); NSCAssert(addedAlias, @"Original implementation for %@ is already copied to %@ on %@", NSStringFromSelector(selector), NSStringFromSelector(aliasSelector), class); // Redefine the selector to call -forwardInvocation:. /** 7.*/ class_replaceMethod(class, selector, _objc_msgForward, method_getTypeEncoding(targetMethod)); &#125; return subject; &#125;&#125; 总体上方法做了以下这些步骤： SEL aliasSelector = RACAliasForSelector(selector); 这个方法得到了字符串拼接 rac_alias_ + @selector 后的方法 aliasSelector 用于后面替换原方法，aliasSelector实际上是被监听方法selector的复制体，因为下面步骤会将监听方法selector替换，所以这里首先要保存一下。 RACSubject *subject 为热信号，检测是否已经在监听改方法，如果有，把信号返回。(关于冷热信号的概念可以查看美团的细说ReactiveCocoa的冷信号与热信号（三）：怎么处理冷信号与热信号) RACSwizzleClass 动态创建好NSObject* Self对象的 RAC 关联类, 这个关联类是继承自NSObject* Self的isa的，类名为 class + _RACSelectorSignal，并把这个映射类的符号添加到 OC 动态类符号当中，然后让对象NSObject* Self的isa指向这个映射类, 然后将 RAC 关联类中的方法转发 forwardInvocation:，完成方法监听. 创建热信号 RACSubject, 并跟 aliasSelector 方法设置为映射关系，方便我们后面直接通过映射获取RACSubject来发送信号 先查看一下对象 object 是否存在被监听的实例方法，如果不存在而查看被监听方法为协议方法 通过 class_addMethod 为关联类增添监听方法selector的复制体aliasSelector, 这样才能方便后面能后调用监听方法selector class_replaceMethod 方法把参数 selector 方法替换成 OC消息转发方法_objc_msgForward，由于selector 方法被替换了，掉用的时候自然都会调用 forwardInvocation: 方法了，但是selector 的实现也消失了，不过我们之前已将创建了复制体——aliasSelector，难道不是吗？结合NSObject文档可以知道，_objc_msgForward 消息转发做了如下几件事： 1.调用resolveInstanceMethod:方法，允许用户在此时为该Class动态添加实现。如果有实现了，则调用并返回。如果仍没实现，继续下面的动作。2.调用forwardingTargetForSelector:方法，尝试找到一个能响应该消息的对象。如果获取到，则直接转发给它。如果返回了nil，继续下面的动作。3.调用methodSignatureForSelector:方法，尝试获得一个方法签名。如果获取不到，则直接调用doesNotRecognizeSelector抛出异常。4.调用forwardInvocation:方法，将地3步获取到的方法签名包装成Invocation传入，如何处理就在这里面了。 通过上面这幅图，可以看出，如果一个 OC 方法在类符号中查找不到的时候，就进行了 _objc_msgForward，而 _objc_msgForward 到最后都会调用到 -forwardInvocation这个 OC 方法，那么RAC的意图就显然易见了，它需要做的，就是利用方法调用时，将所有被监听的方法都运行到-forwardInvocation，通过改造-forwardInvocation方法，利用 RAC 的信号，通知外层监听实现方法。 RACSwizzleClass构建映射类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static Class RACSwizzleClass(NSObject *self) &#123; /** 1.*/ Class statedClass = self.class; Class baseClass = object_getClass(self); Class knownDynamicSubclass = objc_getAssociatedObject(self, RACSubclassAssociationKey); if (knownDynamicSubclass != Nil) return knownDynamicSubclass; NSString *className = NSStringFromClass(baseClass); if (statedClass != baseClass) &#123; /** 2.*/ @synchronized (swizzledClasses()) &#123; if (![swizzledClasses() containsObject:className]) &#123; RACSwizzleForwardInvocation(baseClass); RACSwizzleRespondsToSelector(baseClass); RACSwizzleGetClass(baseClass, statedClass); RACSwizzleGetClass(object_getClass(baseClass), statedClass); RACSwizzleMethodSignatureForSelector(baseClass); [swizzledClasses() addObject:className]; &#125; &#125; return baseClass; &#125; /** 3.*/ const char *subclassName = [className stringByAppendingString:RACSubclassSuffix].UTF8String; Class subclass = objc_getClass(subclassName); if (subclass == nil) &#123; /** 4.*/ subclass = [RACObjCRuntime createClass:subclassName inheritingFromClass:baseClass]; if (subclass == nil) return nil; /** 5.*/ RACSwizzleForwardInvocation(subclass); /** 6.*/ RACSwizzleRespondsToSelector(subclass); /** 7.*/ RACSwizzleGetClass(subclass, statedClass); RACSwizzleGetClass(object_getClass(subclass), statedClass); /** 8.*/ RACSwizzleMethodSignatureForSelector(subclass); objc_registerClassPair(subclass); &#125; /** 9.*/ object_setClass(self, subclass); objc_setAssociatedObject(self, RACSubclassAssociationKey, subclass, OBJC_ASSOCIATION_ASSIGN); return subclass;&#125; object.class 由于KVO重写了class 方法，所以不能准确的找到类.object_getClass() 方法可以准确的找到 isa 指针.object.class 与 object_getClass(object) 进行判断 来防止KVO导致的AOP无效.为什么会发生这种情况？因为当你使用 KVO 的时候，系统会帮你重写类的 class 方法，生成 NSKVONotifying_ + Class。例如如下代码12345678[self.view addObserver:self forKeyPath:@"frame" options:NSKeyValueObservingOptionNew context:nil];- (void)observeValueForKeyPath:(nullable NSString *)keyPath ofObject:(nullable id)object change:(nullable NSDictionary&lt;NSKeyValueChangeKey, id&gt; *)change context:(nullable void *)context &#123; Class statedClass = self.view.class; Class baseClass = object_getClass(self.view); NSLog(@"%@ %@", NSStringFromClass(statedClass), NSStringFromClass(baseClass));&#125; 得到的 log： RACLearning[3657:478602] UIView NSKVONotifying_UIView swizzledClasses() 专门用来存储 isa 被修改过的类，这些类不用重新生成为 RAC 的类. 检查OC类符号表中是否存在经过RAC改造的类 —— Class + _RACSelectorSignal。 不存在改造类的情况下，利用运行时方法objc_allocateClassPair创建继承Class类的类符号——Class + _RACSelectorSignal。 RACSwizzleForwardInvocation 利用运行时替换方式class_replaceMethod将经过改造的类Class + _RACSelectorSignal的消息转发的方法forwardInvocation: 的实现替换成 RAC 的新实现. 由于我们在方法NSObjectRACSignalForSelector将被监听方法selector替换成了_objc_msgForward函数了，所以当我们使用外层API调用respondsToSelector去判断selector是否有实现的时候，很明显会返回false, 而RACSwizzleRespondsToSelector 将经过改造的类Class + _RACSelectorSignal的respondsToSelector:方法实现转而判断aliasSelector是否实现的前提了，前文也说过aliasSelector实际上是被监听方法selector的复制体。 RACSwizzleGetClass让 RAC 让新创建的类Class + _RACSelectorSignal的 class方法的实现全部返回对象NSObject* self的类，也就是类Class + _RACSelectorSignal变成了一个真正的伪装类，为了让对象对自己的身份『说谎』，所有的方法都转发到了这个子类上，如果不修改 class 方法，那么当开发者使用它自省时就会得到错误的类，而这是我们不希望看到的 通过上面图中可以知道，必须为forwardInvocation:提供一个方法签名，才能走运行时转发，所以RACSwizzleMethodSignatureForSelector自然是为类Class + _RACSelectorSignal创建方法签名了. 将对象NSObject *self的isa强制指向经过RAC改造的类 —— Class + _RACSelectorSignal了，这些下来左右调用该对象的所有方法都会访问Class + _RACSelectorSignal类结构体中的MethodList. RACSwizzleForwardInvocation1234567891011121314151617181920212223static void RACSwizzleForwardInvocation(Class class) &#123; SEL forwardInvocationSEL = @selector(forwardInvocation:); Method forwardInvocationMethod = class_getInstanceMethod(class, forwardInvocationSEL); // Preserve any existing implementation of -forwardInvocation:. void (*originalForwardInvocation)(id, SEL, NSInvocation *) = NULL; if (forwardInvocationMethod != NULL) &#123; originalForwardInvocation = (__typeof__(originalForwardInvocation))method_getImplementation(forwardInvocationMethod); &#125; id newForwardInvocation = ^(id self, NSInvocation *invocation) &#123; BOOL matched = RACForwardInvocation(self, invocation); if (matched) return; if (originalForwardInvocation == NULL) &#123; [self doesNotRecognizeSelector:invocation.selector]; &#125; else &#123; originalForwardInvocation(self, forwardInvocationSEL, invocation); &#125; &#125;; class_replaceMethod(class, forwardInvocationSEL, imp_implementationWithBlock(newForwardInvocation), "v@:@");&#125; 定义 IMP 函数指针指针 originalForwardInvocation ，指向 class 类的 forwardInvocation 内部函数实现， 然后创建新的 forwardInvocation: block 函数 newForwardInvocation, block 函数内部先调用 RACForwardInvocation 函数，以调用映射过后的 rac_alias_ + @selector 函数(实际上是 @selector的复制体)，然后给热信号 subject发送信号 Next 以调用订阅 block nexblock. 利用 class_replaceMethod 方法替换了 class 的对象方法 forwardInvocation: 为新的 newForwardInvocation block 函数. RACForwardInvocation12345678910111213141516static BOOL RACForwardInvocation(id self, NSInvocation *invocation) &#123; SEL aliasSelector = RACAliasForSelector(invocation.selector); RACSubject *subject = objc_getAssociatedObject(self, aliasSelector); Class class = object_getClass(invocation.target); BOOL respondsToAlias = [class instancesRespondToSelector:aliasSelector]; if (respondsToAlias) &#123; invocation.selector = aliasSelector; [invocation invoke]; &#125; if (subject == nil) return respondsToAlias; [subject sendNext:invocation.rac_argumentsTuple]; return YES;&#125; 由 NSObjectRACSignalForSelector 中知道，热信号 subject 已经被创建了， 而且利用了 class_addMethod 方法完成了被监听方法 @selector 的复制体 rac_alias_ + @selector 方法，所以这里直接利用 [invocation invoke]调用 rac_alias_ + @selector 方法，然后再像热信号 subject 发送 next 信号并且带上 rac_alias_ + @selector 方法的参数数组rac_argumentsTuple以调用 nextblock. rac_argumentsTuple123456789- (RACTuple *)rac_argumentsTuple &#123; NSUInteger numberOfArguments = self.methodSignature.numberOfArguments; NSMutableArray *argumentsArray = [NSMutableArray arrayWithCapacity:numberOfArguments - 2]; for (NSUInteger index = 2; index &lt; numberOfArguments; index++) &#123; [argumentsArray addObject:[self rac_argumentAtIndex:index] ?: RACTupleNil.tupleNil]; &#125; return [RACTuple tupleWithObjectsFromArray:argumentsArray];&#125; 参数个数 methodSignature.numberOfArguments 默认有一个 _cmd 一个 target 所以要 -2 获取该方法的参数 ，rac_argumentAtIndex 函数内通过 methodSignature 的 getArgumentTypeAtIndex 方法来判断获取 OC 对象或 基础类型(如 int，char，bool 等)转成的 NSNumber 对象。 ?: 新写法，如果有则添加返回的 OC 对象，没有就把 RACTupleNil.tupleNil 单例对象添加进去（为什么添加单例对象？可以节省内存！） 利用 RACTuple 对象吧参数数组包装一下返回。 RACSwizzleRespondsToSelector12345678910111213141516171819static void RACSwizzleRespondsToSelector(Class class) &#123; SEL respondsToSelectorSEL = @selector(respondsToSelector:); Method respondsToSelectorMethod = class_getInstanceMethod(class, respondsToSelectorSEL); BOOL (*originalRespondsToSelector)(id, SEL, SEL) = (__typeof__(originalRespondsToSelector))method_getImplementation(respondsToSelectorMethod); id newRespondsToSelector = ^ BOOL (id self, SEL selector) &#123; Method method = rac_getImmediateInstanceMethod(class, selector); if (method != NULL &amp;&amp; method_getImplementation(method) == _objc_msgForward) &#123; SEL aliasSelector = RACAliasForSelector(selector); if (objc_getAssociatedObject(self, aliasSelector) != nil) return YES; &#125; return originalRespondsToSelector(self, respondsToSelectorSEL, selector); &#125;; class_replaceMethod(class, respondsToSelectorSEL, imp_implementationWithBlock(newRespondsToSelector), method_getTypeEncoding(respondsToSelectorMethod));&#125; 更换改造类class + _RACSelectorSignal的respondsToSelector方法，让aliasSelector方法成为真正的被监听方法selector的复制体 实际上，整个调用过程就是如下图所示:]]></content>
      <categories>
        <category>源码分析</category>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
</search>
